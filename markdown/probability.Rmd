# Probability to describe uncertainty {#probability}

```{r package-load-probability, include=FALSE}
# check and load the libraries
library("igraph")
library("ggthemes")
library("kableExtra")
library("tidyverse")
library("plotly")
library("grid")
library("plyr")

source("./code/useful-variables.R")
source("./code/helper-functions.R")
```

We saw in the previous chapter that there is uncertainty in scientific evidence. By asking a few simple questions about the uncertainties in a particular context, we demonstrated a systematic approach to assessing the uncertainty which can easily be applied to forensic evidence. As part of this process, the expert assesses the magnitude of their personal uncertainty given the scientific expertise and experience that they have, e.g. out of every 1000 similar case circumstances, the expert believes 200 would yield a fibre match if the suspect had truly been at the crime scene. This magnitude is based upon a probability assignment by the expert. In this chapter we discuss probability, describing what it is and using examples to demonstrate some of its useful properties as a framework for handling uncertainty.

## Quantifying uncertainty

Quantifying uncertainty is a systematic way of assimilating and comparing uncertainties. This means that different personal uncertainties for the same object can be assessed consistently and also that personal uncertainties for different objects can be compared. This is because the framework of mathematics forces quantities to obey a coherent and consistent set of logical rules. The subset of mathematics which handles uncertainty is known as probability. The main benefit of using probability is the framework of logic that it enforces, rather than the quantification of uncertainty (although this is useful).

A probability is a number between 0 and 1 that describes the magnitude of uncertainty for the occurrence of an event. The probability must obey certain rules which we will show in subsequent examples in this chapter. A probability of 0 means that the event is impossible whilst a probability of 1 means that an event is certain. Uncertainty is described by probabilities which fall between 0 and 1. Probabilities of 0.5 describe an event whose occurrence is exactly as likely as its non-occurrence. Events whose occurrence is less likely than not should have a probability less than 0.5 on the scale, whilst events whose occurrence is more likely than not should have a probability greater than 0.5 on the scale. How close these probabilities are to 0 and 1 should reflect an individual's magnitude of uncertainty. Since uncertainty is personal then it follows that probabilities are personal too. In forensic science, personal probabilities are generally interpreted as an individual's degree of belief in the occurrence of an event. Not everyone agrees with this interpretation, but this historical debate is outside the scope of this book.

Constructing probabilities to describe uncertainty is often done by assuming a probabilistic **model** for how the uncertainty is expected to behave in reality. Since the process that is being modelled is uncertain, the expectations might not be exactly what is observed in practice. The most useful models can accurately align an individual's magnitude of uncertainty to a quantitative probability, accepting that this can never be done perfectly.

We focus only on quantifying direct uncertainty, since this is what is done in practice when interpreting evidence. Verbal qualifiers are given for indirect uncertainties instead and are not covered here.

## Example: coin toss {#single-coin-toss}

The outcome of a coin toss is uncertain in most cases. We can consider some of the questions from the previous section to describe this uncertainty.

**What uncertainties are there?** 

The uncertainty is whether the coin will land heads-up or tails-up as a result of the toss.

**What are the sources of this uncertainty?** 

* the coin toss process
  + aleatory uncertainty: there is randomness to the coin toss process
  + epistemic uncertainty: is the person tossing the coin able to do so without favouring one side of the coin over the other? This can be reduced by learning about the person tossing the coin, e.g. from previous tosses.
* potential double sided coin
  + epistemic uncertainty: can be eliminated by checking both sides of the coin

Assume that the coin is checked and has one head and one tail, and that the person tossing the coin is doing so fairly. There is now only aleatory uncertainty about the outcome. This is an irreducible uncertainty about the coin toss. 

**What is the magnitude of uncertainty?** 

The coin toss has only two possible outcomes, head or tail. The probability that one of these outcomes must occur is 1, since it is certain. This means that the events are **exhaustive**, i.e. the events exhaust all possible outcomes.

A head and a tail cannot occur together and so they are also known as **mutually exclusive**. When outcomes are mutually exclusive, then their probabilities can be added together - this is one of the laws of probability. Because both outcomes of the coin toss are also exhaustive then this means that whatever the probability of the individual outcomes, they must sum to 1.
<!-- [MAYBE ADD VENN DIAGRAM FOR VISUAL AID] -->

If a head and a tail are equally likely, then due to the rules above they must each have a probability equal to 0.5. This quantified uncertainty is the result of the logic of probability. These values form a probability model for the outcomes of the coin toss. This probability model can be checked to confirm that it aligns with specified beliefs. For example, since we hold the belief that each probability is 0.5, then we expect that the outcomes of multiple coin tosses should be evenly distributed between heads and tails. 

Notice that if we did not ignore some of the epistemic uncertainties about the coin toss (e.g. if we did not trust the coin flipper to be fair), then the probability model would need to be adjusted to align with this belief, e.g. by changing the probability of heads from 0.5.

```{block eval=FALSE, include=isDynamicOutput()}
## Interactive coin toss

In the example below, there are two tree diagrams. The probability tree displays the degree of belief for the coin toss in terms of the probabilities for the outcomes. The expected frequency tree displays the expected number of heads and tails corresponding to those probabilities for a fixed number of coin tosses. 

Use the sliders below to change the probability of heads for the coin toss and also the number of tosses with which to view the expected outcomes. Firstly, fix the probability of heads to 0.5, since this is what we did in the example above. Then change the number of tosses to see that the expected number of heads and tails are equal. Next, fix the probability of heads to another number and see how this affects the expected outcomes.

```
```{r echo=FALSE}
if(isDynamicOutput()){
  knitr::include_app(getInteractiveLink("tabCoinTree",NULL,TRUE), height = '750px')
}
```
```{block eval=FALSE, include=isDynamicOutput()}
The expected frequency tree in the example above shows what the probability model expects to occur for a specified probability of a head. It does not necessarily show what will be observed in practice because there is an unavoidable uncertainty about the outcomes (aleatory uncertainty). Tossing the coin, observing the outcomes, and then using that to refine the probability model falls into the realm of statistics, which is not covered in this book. Interactive examples exploring this topic can be found in our [online application](https://lrcfs.dundee.ac.uk/apps/interactive-lr/).
```
<!-- ```{block eval=TRUE, include=!isDynamicOutput()} -->
<!-- ### Expected frequency tree -->

<!-- Below is an example of an expected frequency tree. The expected frequency tree displays the expected number of heads and tails corresponding to the probabilities of heads and tails for a fixed number of coin tosses.  -->

<!-- A probability of heads of 0.5 means that we expect 5000 or every 10,000 tosses to result in heads, and the other 5000 to result in tails. -->

<!-- ``` -->
<!-- ```{r echo=FALSE, freq-tree-coin-toss, echo=FALSE, fig.cap="An expected frequency tree diagram of the coin toss example. Out of 10,000 cosses, we expect 5000 to be heads and 5000 to be tails. The probability of heads is 0.5 and is equal to the probability of tails. ", out.width = '80%', fig.align = 'center'} -->
<!-- if(!isDynamicOutput()){ -->
<!--   e <- c(1, 2, 1, 3) -->
<!--   v <- c("10,000\ntosses", "5000\nheads", "5000\ntails") -->
<!--   createBinaryTree(e,v) -->
<!-- } -->
<!-- ``` -->

<!-- To view all of the interactive examples in this book, please visit [Interactive Stats Book](`r getInteractiveLink()`) (`r getInteractiveLink()`). -->

## Personal probabilities

We mentioned in the previous section that probability was personal because individuals have different knowledge and beliefs. Some differences in beliefs might be more or less reasonable since they can be based upon more or less reliable information. 

Probability assignments based upon more reliable and generally agreed information will be more **objective**. For example, the scientific evidence underlying the processing and analysis of full DNA profiles for single donors is well established and so experts are generally confident and in agreement about assigning probabilities in this circumstance.

Probability assignments which are based upon less reliable or less generally agreed information will be more **subjective**. For example, the transfer and persistence of DNA on surfaces is an active area of research for scientists and so probabilities involving these circumstances may be subjective. Subjective probabilities are not necessarily bad because they can still be the best assessment of the available knowledge. This might happen for example when there is very limited published scientific literature about a particular scenario. Even though there is limited published information, an expert may have relevant previous case experience in that scenario and so may be able to assign subjective probabilities. In other words, subjective probability assignments are not necessarily (and should not be) arbitrary.

For repeatable events like the coin toss we can check and update our probabilities using empirical data, e.g. repeated tosses of the coin. This can be seen as gaining a better understanding of the aleatory uncertainty about the distribution of the outcomes and eliminating epistemic uncertainty about whether the coin tossing process was being done fairly. With enough repetition, personal probabilities which were initially different between individuals can converge to the same value as more objective information becomes known. In criminal cases, the opportunity to repeat events and gather scientific data from the same case circumstances can be limited. This is because some events are one-off and difficult (if not impossible) to completely replicate in scientific experiments. In these situations, probabilities can still be informed by other available empirical data however, e.g. by observations from similar circumstances, and can also still be informed by expert knowledge. This knowledge should be disclosed and be available for audit by the court.

## Conditioning on information

Information which is used to construct a probability is called **conditioning** information. This is because we are constructing a probability which is conditional on that information, otherwise known as a **conditional probability**. The process of using information this way to construct such a conditional probability is itself called **conditioning**.

This means that probability is conditional on our current state of individual knowledge. Conditioning information can be broken down into two types:

* information that is emphasised in the conditioning of the probability. This information is explicit and critical to the application of the probability. For example, the hypotheses of the prosecution and defence.
* all other information. This includes assumptions and other contextual information, otherwise known as **background information**. An example of this is the relevant case circumstances that are agreed by both the prosecution and defence. This information can be tedious to state each time a probability is mentioned and so it is often stated once and then only mentioned again if it changes. 

The distinction between these two types of information is context-dependent since it is just a matter of emphasising different contextual information. Information that is important to emphasise in one context may be background information in another. For example, when interpreting fibre evidence recovered from a crime scene, the expert may wish to condition on the person of interest having been present at the crime scene. This would be background information in a case in which the person of interest admits to having been present at the crime scene. Otherwise it would be disputed by the person of interest and thereby become a critical piece of conditioning information. 

## Conditioning on the past and future

A useful application of conditional probability is to condition on possible outcomes of future events to see how this affects probabilities of interest. For example, banks who lend money will need to consider the probability that loanees will be able to repay that money (with interest). A future event which would affect that probability could be the lonees' employment status. If their employment is unstable and their probability of repayment would greatly decline if they were to lose their job, then the bank might be less likely to lend to them compared to if their probability of repayment was unaffected by their employment status (e.g. if they own physical assets that the bank could seize if they fail to repay). Considering possible future events and risks helps to make uncertain decisions in the present. 

We can also condition on possible events in the past. This is useful for example when the causes of past events are unknown. This is epistemic uncertainty. In this case, we can consider the probability of the observed outcome conditioned on multiple candidate causal events. These conditional probabilities can then be compared to determine the support of each of the causal events for the observed outcome. This is how conditional probabilities are used for interpreting forensic evidence: we look at the events which the defence and prosecution assert and compare how likely the observed evidence would have been when it is conditioned on each hypothesis. For example, when interpreting fibre evidence recovered from the clothing of a person of interest, the expert must consider how probable this evidence would have been in light of what both the prosecution and defence claim to have happened.

## Example: double coin toss {#double-coin-toss}

Suppose now that we toss 2 coins, labelled coin 1 and coin 2. Coin 1 is tossed first and the outcome is recorded. Then coin 2 is tossed and its outcome is recorded. Both coins are tossed in such a way that guarantees a 0.5 probability of a head. The outcome of the toss of coin 1 can be used as conditioning information to see how it affects the probabilities of the outcomes of coin 2. This means that the uncertainty of interest is the toss of coin 2 conditioned on the outcome of the toss of coin 1. Question: what is the probability of getting a head with coin 2 after coin 1 has shown a head?

Conditioning information:

* coin 1 showing head
* background information - each coin has a 0.5 probability of a head.

With the above conditioning information the question becomes: is the outcome of coin 2 affected by the outcome of coin 1? If not, then the answer to the original question is 0.5 since the background information guarantees a 0.5 probability of a head for coin 2. The idea that the outcome of coin 2 is unaffected by the outcome of coin 1 is known as **independence**. This can sometimes be missed as an underlying unchecked assumption. It is helpful to add this to the background information so that the probability model is fully specified. All relevant assumptions can then be assessed by someone else.

Updated conditioning information:

* coin 1 showing head
* background information - each coin has a 0.5 probability of a head, tosses from coin 1 and 2 are independent of one another.

Figure \@ref(fig:freq-tree-double-coin) shows an expected frequency tree for this information for 10,000 tosses of the coins.

```{r freq-tree-double-coin, echo=FALSE,fig.cap="An expected frequency tree diagram of the double coin toss example. Out of every 10,000 double coin tosses, we expect 2500 to be double heads. The probability of getting two heads is 0.25.", out.width = '80%', fig.align = 'center'}
e <- c(1, 2, 1, 3, 2, 4, 2, 5, 3, 6, 3, 7)
v <- c("10,000 \ntosses", "5000\ncoin 1 heads", "5000\ncoin 1 tails", "2500\ncoin 2 heads", "2500\ncoin 2 tails", "2500\ncoin 2 heads", "2500\ncoin 2 tails")
createBinaryTree(e,v)
```

After the 5000 tosses in which coin 1 is heads we expect 2500 heads from coin 2. This reflects the belief that coin 2 has a 0.5 probability of a head and is independent of coin 1. 

The expected frequency tree can also help to answer other questions, such as: what is the probability of both coins showing a head? Out of the 10,000 tosses, 2,500 are expected to result in both coins showing heads. This reflects the belief that there is a $\frac{2500}{10000}=\frac{1}{4}=0.25$ probability of obtaining a double heads.

```{block eval=FALSE, include=isDynamicOutput()}
## Interactive double coin toss

The example below displays the probability and expected frequency trees for the double coin toss. If the plots are not displaying correctly, then please refresh your page. You can view this example and others in our [online application](https://lrcfs.dundee.ac.uk/apps/interactive-lr/). Use the sliders below to change the probability of a head for both coins and also the number of double tosses for the expected outcomes. Here is an activity to try:

The **multiplication rule** for independent events states that the probability of two independent events both occurring can be obtained by multiplying the probability of each independent event together. Verify that this probability model for the double coin toss satisfies the multiplication rule by:

* Finding the probability for double heads on the probability tree and checking that it equals the probability of a head multiplied by itself. (Use an online calculator if needed!)
* Working out the probability of tails from the probability of heads. (Hint: they are exhaustive and mutually exclusive.)
* Finding the probability for double tails on the probability tree and checking that it equals the probability of a tail from the previous step multiplied by itself.
* Finding the probability of a coin 1 head with a coin 2 tail on the probability tree and checking that it equals the probability of a head multiplied by the probability of a tail. (This is the same for a coin 1 tail with a coin 2 head.)
* Changing the probability of a head to another number and repeating the previous steps once more.
  
```
```{r echo=FALSE}
if(isDynamicOutput()){
  knitr::include_app(getInteractiveLink("tabDoubleCoinTree",NULL,TRUE), height = '800px')
}
```

## Example: coin toss game

We can also consider two events for the same example which are not independent. Suppose there is a game that is decided by the result of the double coin toss. Player 1 wins if the coin tosses result in double heads and player 2 wins if the coin tosses result in double tails. If neither player wins then a draw is called and the coins are tossed again. Since double heads is just as likely as double tails, the probability is 0.25 for each, then both players are equally likely to win prior to the first coin being tossed. We can see this from the highlighted Figure \@ref(fig:freq-tree-double-coin-bet) below.

```{r freq-tree-double-coin-bet, echo=FALSE,fig.cap="An expected frequency tree diagram of the double coin toss game. Out of every 10,000 tosses, 2500 are double heads and 2500 are double tails. This means that each player has equal an probability of winning of 0.25. The remaining 5000 tosses result in a draw and so the probability of a draw is 0.5.", out.width = '80%', fig.align = 'center'}
e <- c(1, 2, 1, 3, 2, 4, 2, 5, 3, 6, 3, 7)
v <- c("10,000\ntosses", "5000\ncoin 1 heads", "5000\ncoin 1 tails", "2500\ncoin 2 heads\nplayer 1 wins", "2500\ncoin 2 tails\ndraw", "2500\ncoin 2 heads\ndraw", "2500\ncoin 2 tails\nplayer 2 wins")
fw <- c(1, 1, 1, 2, 1, 1, 2)
createBinaryTree(e,v,fw)
```

Out of 10,000 double tosses, player 1 is expected to win 2500, player 2 is expected to win 2500, and 5000 double tosses are expected to result in a draw. However, whilst the outcome of coin 1 does not affect the outcome of coin 2, it does affect the winning probabilities for this game. For example, we can condition on coin 1 being a head as before.

Conditioning information:

* coin 1 showing head
* background information - each coin has a 0.5 probability of a head, tosses from coin 1 and 2 are independent of one another.

With the above conditioning information (i.e. only considering the left-hand branch of the tree), there is now a 0.5 probability that player 1 wins (2,500 out of 5,000), a 0.5 probability that there is a draw (2,500 out of 5,000), and it is impossible that player 2 wins in this round (0 out of 5,000). Conditioning on coin 1 being heads has increased the probability of player 1 winning from 0.25 to 0.5, and it has decreased the probability of player 2 winning from 0.25 to 0. The opposite occurs when the outcome of coin 1 is a tail. The probability of a draw remains unchanged at 0.5 before coin 1 is tossed, and 0.5 after it is tossed regardless of the result. In summary, the winning outcomes are not independent of the result of coin 1, but the draw is independent of it.

## Odds

Odds are another way of expressing probabilities. Odds are given as a ratio of probabilities so that it is clear how much more or less likely one event is compared to another. In this sense, probability is an absolute measure of uncertainty, whilst odds are a relative measure of uncertainty. Any two probabilities can be compared together to create odds. One pair which is commonly used is the probability of an event occurring versus the probability of the same event not occurring.

For example, the coin toss was just as likely to result in a head as it was to result in a tail. This is expressed as odds written as 1:1, which is spoken as '1-to-1' or more commonly 'evens'. Odds of 1:1 means that we can separate the possible outcomes into a total of $1+1=2$ parts which are equally probable. One part represents the probability of a head and the other part represents the probability of a tail.

We can convert from odds to probability for exhaustive events as follows. For the single coin toss we had odds of 1:1 for heads. The total probability, which must be 1, is made up of 2 equally sized parts. One of these parts represents a head, and so the probability of a head (and similarly for a tail) is $\frac{1}{2}=0.5$. Suppose instead we have odds of 1:9 for an event occurring versus not occurring. This means that the total probability, which must be 1, is made up of 10 equally sized parts. One of these ten parts represents the event occurring, and so its probability is $\frac{1}{10}=0.1$. The other nine parts represent the event not occurring, and so the probability of non-occurrence is $\frac{9}{10}=0.9$, Odds which are used to represent probabilities before any conditioning occurs (or are only conditioned on background information), are known as **prior odds**. The conversion from odds to probabilities is more challenging when the events are not exhaustive, but we do not consider that here.

Converting from probabilities to odds is much simpler since we only measure how much bigger one probability is than the other. For example, the probability of player 1 winning the double coin toss game  by getting double heads was 0.25. That meant that the probability of player 1 not winning before any coins had been tossed was 0.75. Since the probability of player 1 not winning (0.75) was three times larger than the probability of player 1 winning (0.25), the prior odds of player 1 winning were 1:3.

Prior odds can be updated using conditioning information. These updated odds are known as **posterior odds**. For example, as part of the double coin toss game we conditioned on the result of coin 1 being a head. Before the conditioning, the probability of player 1 winning was 0.25; the prior odds of player 1 winning were 1:3. Conditioning on coin 1 being a head resulted in the probability of player 1 winning rising to 0.5. This means that the posterior odds (i.e. **after** observing coin 1 being a head) of player 1 winning versus not winning were evens (1:1) for that round. 

Another reason that odds are useful is because of the simplicity that they give to a very important mathematical result, which we discuss in the next section. 

## Bayes' rule {#bayes}

Suppose we have a probability assigned for an event $A$ and we observe an event $E$ that is relevant to $A$. How should we update the probability assigned to $A$ in light of the relevant information from $E$? An example is a personal probability that it will rain next Saturday. Then on Friday, it rains throughout the day and into the evening. Your personal probability might increase now that you have observed rain just prior to your original probability assignment. But by how much should it increase exactly? This is a useful question that is answered using Bayes' rule.

<!-- 1. use the multiplication rule of probability to derive Bayes' rule for the probability of an event $A$ in light of information from an event $E$, -->
<!-- 2. state Bayes' rule for the probability of another event $B$ in light of information from the same event $E$, -->
<!-- 3. divide the conditional probability from step 1 by the conditional probability from step 2 in order to obtain posterior odds of $A$ to $B$ in light of $E$. -->

<!-- We go through these steps below in order to gain an intuition behind Bayes' rule. -->

<!-- **1. use the multiplication rule of probability to derive Bayes' rule for the probability of an event $A$ in light of information from an event $E$** -->

<!-- For events $A$ and $E$, the multiplication rule from Section \@ref(double-coin-toss) states that the joint probability of $A$ and $E$ co-occurring is -->
<!-- $$\text{probability of }A \text{ and }E = \text{probability of }A \text{ conditioned on }E \times \text{probability of }E.$$ -->
<!-- The joint probability can be expressed differently by conditioning on $A$ instead of $E$: -->
<!-- $$\text{probability of }A \text{ and }E = \text{probability of }E \text{ conditioned on }A \times \text{probability of }A.$$ -->
<!-- These two expressions are equivalent since they describe the same joint probability. This means that we can write the following: -->
<!-- \begin{align*} -->
<!--   &\text{probability of }A \text{ conditioned on }E \times \text{probability of }E \\ -->
<!--   &=\text{probability of }E \text{ conditioned on }A \times \text{probability of }A. -->
<!-- \end{align*} -->
<!-- Since we are interested in an expression for the probability of $A$ conditioned on $E$, we can isolate that term by dividing both sides of the equation above by the probability of $E$ (assuming it is not equal to zero). This gives Bayes' rule: -->
<!-- $$ \text{probability of }A\text{ conditioned on }E = \frac{\text{probability of }E\text{ conditioned on }A \times \text{probability of }A}{\text{probability of }E}.$$ -->

<!-- **2. state Bayes' rule for the probability of another event $B$ in light of information from the same event $E$** -->

<!-- Similarly for another event $B$, that is also related to $E$, Bayes' rule states: -->
<!-- $$ \text{probability of }B\text{ conditioned on }E = \frac{\text{probability of }E\text{ conditioned on }B \times \text{probability of }B}{\text{probability of }E}.$$ -->

<!-- **3. divide the conditional probability from step 1 by the conditional probability from step 2 in order to obtain posterior odds of $A$ to $B$ in light of $E$** -->

<!-- Dividing the terms in the equation for $A$ by the equation for $B$ gives a formula for the ratio of the probabilities of $A$ and $B$: -->
<!-- $$ \frac{\text{probability of }A\text{ conditioned on }E}{\text{probability of }B\text{ conditioned on }E}=\frac{\text{probability of }E\text{ conditioned on }A}{\text{probability of }E\text{ conditioned on }B}\times \frac{\text{probability of }A}{\text{probability of }B},$$ -->
<!-- where the probability of $E$ from both equations cancels out and so is ignored. The terms on the left hand side of the equation are the posterior odds of $A$ to $B$ conditioned on $E$. The ratio on the far right hand side is the prior odds of $A$ to $B$. When expressed like this, Bayes' rule provides a link between the prior and posterior odds:   -->
<!-- $$\text{posterior odds of }A\text{ to } B=\frac{\text{probability of }E\text{ conditioned on }A}{\text{probability of }E\text{ conditioned on }B}\times \text{prior odds of }A\text{ to }B.$$ -->

**Bayes' rule** is a mathematical rule for updating probability assignments in light of new information. For an event of interest $A$ and  new information from an event $E$, the probability version of Bayes' rule is: 
$$ \text{probability of }A\text{ conditioned on }E = \frac{\text{probability of }E\text{ conditioned on }A \times \text{probability of }A}{\text{probability of }E}.$$
It provides a means of obtaining a conditional probability for the event of interest based upon the new information (the left-hand side of the equation) by using probabilities that may already be assigned (the right-hand side of the equation).

For the odds of two events $A$ and $B$ in light of $E$, Bayes' rule is can also be expressed as:
$$ \frac{\text{probability of }A\text{ conditioned on }E}{\text{probability of }B\text{ conditioned on }E}=\frac{\text{probability of }E\text{ conditioned on }A}{\text{probability of }E\text{ conditioned on }B}\times \frac{\text{probability of }A}{\text{probability of }B},$$
The terms on the left hand side of this equation are the posterior odds of $A$ to $B$ conditioned on $E$. The ratio on the far right hand side is the prior odds of $A$ to $B$. When expressed like this, Bayes' rule provides a link between the prior and posterior odds:  
$$\text{posterior odds of }A\text{ to } B=\frac{\text{probability of }E\text{ conditioned on }A}{\text{probability of }E\text{ conditioned on }B}\times \text{prior odds of }A\text{ to }B.$$

This rule states that the posterior odds of $A$ to $B$ (conditioned on $E$) are a product of the prior odds of $A$ to $B$ multiplied by a ratio of probabilities for $E$ conditioned on $A$ and $B$, respectively. This ratio is known as the **Bayes factor**, or **likelihood ratio** (LR) in this instance. The LR acts as the updating factor for the prior odds due to the event $E$. It describes how much more (or less) probable event $E$ is when conditioned on $A$ compared to when it is conditioned on $B$. We focus on the LR in Chapter \@ref(likelihood-ratio).

Bayes' rule gives us mathematical expressions that probability assignments must obey. This is another means of assuring logical values for conditional probability assignments. It does not remove subjectivity from the probability or odds assignment, but it does remove subjectivity from how that probability or odds assignment should be updated in light of new information.

Bayes' rule switches the conditioning information as we move from the LR to the posterior odds. Probabilities for $E$ which are conditioned on $A$ and $B$ in the LR are switched to probabilities for $A$ and $B$ conditioned on $E$ in the posterior odds. This is known as **transposing the conditional**. Bayes' rule gives us the correct way to transpose the conditional using the logic of probability. The legal domain has a tricky and tempting trap for incorrectly transposing the conditional, known as the **prosecutor's fallacy**. We show this in Chapter \@ref(propositions).

## Example: guessing coin 1

In this example we alter the double coin tossing game from Section \@ref(double-coin-toss). Suppose that player 1 now tosses the coins and hides the outcomes from player 2. After tossing the coins, player 1 only tells player 2 whether double tails were tossed or not. If double tails were tossed, then player 2 is given a chance to win by guessing the outcome of coin 1. If their guess is correct, then player 2 wins. Assume that the coins are tossed and player 2 is given the option to guess, what should their guess be?

Background information:

* player 1 tells the truth,
* player 1 tosses the coins in such a way that the odds are even for heads and tails for each coin,
* a double tails was not tossed (as this is why player 2 was given the option to guess).

This is a situation of epistemic uncertainty. Before the coin tosses, there is aleatory uncertainty - an unavoidable randomness to the future outcomes of these coin tosses. After the coin tosses, there is only epistemic uncertainty - player 1 knows the outcomes but player 2 does not. 

Player 2 can use probabilities to make the best guess for the outcome of coin 1. The possible outcomes of the double coin toss are presented as an expected frequency tree in Figure \@ref(fig:freq-tree-double-coin-bet-2) below.

```{r freq-tree-double-coin-bet-2, echo=FALSE,fig.cap="An expected frequency tree diagram of the coin guessing game. Outcomes other than double tails occur in 7500 out of the original 10,000 tosses (highlighted in bold).", out.width = '80%', fig.align = 'center'}
e <- c(1, 2, 1, 3, 2, 4, 2, 5, 3, 6, 3, 7)
v <- c("10,000\ntosses", "5000\ncoin 1 heads", "5000\ncoin 1 tails", "2500\ncoin 2 heads", "2500\ncoin 2 tails", "2500\ncoin 2 heads", "2500\ncoin 2 tails")
fw <- c(1, 1, 1, 2, 2, 2, 1)
createBinaryTree(e,v,fw)
```

The best guess can be logically reasoned both with and without using Bayes' rule.

## Coin guess without Bayes' rule

```{r freq-tree-double-coin-bet-without-bayes, echo=FALSE,fig.cap="An expected frequency tree diagram of the coin guessing game. Outcomes other than double tails occur in 7500 out of the original 10,000 tosses (highlighted in bold). Out of those 7500 double tosses, 2500 came from coin 1 being tails, and 5000 came from coin 1 being heads. Since twice as many possible outcomes originate from coin 1 being heads the posterior odds of coin 1 being a head are 2:1.", out.width = '80%', fig.align = 'center'}
e <- c(1, 2, 1, 3, 2, 4, 2, 5, 3, 6, 3, 7)
v <- c("10,000\ntosses", "5000\ncoin 1 heads", "5000\ncoin 1 tails", "2500\ncoin 2 heads", "2500\ncoin 2 tails", "2500\ncoin 2 heads", "2500\ncoin 2 tails")
fw <- c(1, 1, 1, 2, 2, 2, 1)
createBinaryTree(e,v,fw)
```

Since a double tails did not occur, Player 2 knows that one of the following three outcomes must have occurred: 

1. *either* coin 1 was a head and coin 2 was a head, 
2. *or* coin 1 was a head and coin 2 was a tail, 
3. *or* coin 1 was a tail and coin 2 was a head. 

Figure \@ref(fig:freq-tree-double-coin-bet-without-bayes) shows that for every 10,000 double tosses, the three outcomes above are expected in 7500 cases. In 5000 of these 7500, coin 1 is a head. In the other 2500, coin 1 is a tail. There are twice as many outcomes in which coin 1 is a head (5000 compared to 2500) and so the odds are 2:1 in favour of coin 1 being heads. These represent posterior odds, with the conditioning information being the fact that double tails has not occurred.

This means that player 2 should always guess a head when given the choice in this game, since the odds will be in their favour. This result might seem counter-intuitive at first glance. The key thing to understand is that the information that double tails has not occurred should update player 2's belief about the possible outcomes of the tosses.

## Coin guess using Bayes' rule

We can verify that posterior odds of 2:1 in favour of coin 1 being heads are correct by using Bayes' rule. Event $A$ from Bayes' rule in this example is coin 1 being a head and event $B$ is coin 1 being a tail, since these are the options that player 2 must decide between. Event E is the knowledge that the result was not a double tails, since this is the information that player 1 reveals. This results in the following application of Bayes' rule:
$$\text{posterior odds of coin 1 head to coin 1 tail}=\text{LR} \times \text{prior odds of coin 1 head to coin 1 tail},$$
where the LR equals the following ratio of conditional probabilities
$$\text{LR}=\frac{\text{probability of no double tails conditioned on coin 1 head}}{\text{probability of no double tails conditioned on coin 1 tail}}.$$
To apply Bayes' rule, we need to assign the probabilities underlying the LR and the prior odds of coin 1 head to coin 1 tail.

The LR in this example considers the following question: how much more (or less) probable is it to toss something other than double tails if coin 1 is a head compared to if coin 1 is a tail? We can inspect the numerator and denominator of the LR separately.

**LR - numerator**: This is the probability of no double tails conditioned on coin 1 being a head. If coin 1 is a head, then it is certain that a double tails will not be tossed. That means that this probability is 1.

**LR - denominator**: This is the probability of no double tails conditioned on coin 1 being a tail. Out of every 5000 tosses in which coin 1 is tails, we expect 2500 to lead to coin 2 being heads and 2500 to lead to coin 2 being tails. The outcomes are evenly split because the probability is 0.5. 

**LR**: These probabilities result in an LR of $\frac{1}{0.5}=2$. In other words, an outcome other than double tails is twice as likely when coin 1 is a head compared to when coin 1 is a tail.

**Prior odds**: The second component of Bayes' rule that we needed was the prior odds of coin 1 being a head. These odds are evens as they were given by the background information for the tosses of the coins, i.e. the coins are tossed so as to guarantee even odds of heads and tails. The prior odds of coin 1 showing a head are 1:1.

Bayes' rule states that the posterior odds must be equal to the prior odds multiplied by the LR. With an LR of 2 and prior odds of 1:1, we obtain posterior odds of 2:1 in favour of a head; coin 1 is twice as likely to be a head when we know the outcome is not double tails. This result is the same as when we reasoned without using Bayes' rule, and so we have verified that it satisfies Bayes' rule. 

In this example it was possible to calculate the posterior odds without using Bayes' rule. This meant that the odds could be verified. In many real situations, the posterior odds are hard to quantify without using Bayes' rule. Bayes' rule offers an powerful and elegant solution to this problem since the prior odds and LR are often easier to quantify.

## Reliable probabilities {#reliable-probabilities}

Probability in forensic science is subjective and personal. Anyone is capable of assigning a probability to their personal uncertainties. Even if everyone does this to the best of their ability, some people are better suited to assigning probabilities to certain events than others. This supports the idea of experts versus non-experts: the expert's probability assignment for a situation within their expertise will be more **reliable** than that of the non-expert. The expert has more knowledge about a field and so their best assessment is better than that of an uninformed non-expert. Reliability of probability assignments is a key part of interpreting and using expert evidence.

Factors that affect the reliability of a probability assignment include:

* assessability
  + This property describes whether sufficient information is available about the probability assignment in order to be adequately assessed. Are all assumptions stated explicitly? Is the probability explicitly stated? Are any underlying data independently accessible? Probabilities must be assessable in order to be classified as reliable or not.
* background information
  + This property refers to the reliability of the background information of a probability assignment. Is the background information that underpins the probability generally agreed in the expert's field or is it more subjective? What reasoning has been used to include the background information? Do reasonable changes to the background information greatly affect the probability assignment?
* calibration
  + This property refers to the degree of error in expert probability assignments. For example, weather forecasters are tasked with providing probabilities for rain in a particular region of interest throughout each day. Their calibration can be measured by comparing their historical probability assignments to whether rain actually occurred or not over a long period of time. Forecasters who assign high probabilities of rain when it actually does rain and low probabilities when it actually does not rain are well calibrated. Better calibration leads to greater reliability. Experts in forensic science can demonstrate this in multiple ways, e.g. by using an empirically well-calibrated statistical model and by performing competency tests.
* validation
  + This property aims to verify the entire process of the probability assignment (and not just the quantitative measurements as in calibration above). This includes checking the consistency, calibration, and appropriateness of the probability assignment to the case at hand. Depending on the case, this could mean validating the reliability and relevance of data that has been used as well as the calibration and output of any statistical models. 
  
None of the above properties can guarantee that a reliable probability assignment has been made under all circumstances. They only provide a general idea of what to consider when assessing reliability. Assignments in real cases require assessing the above properties as well as others not listed here.

## Base rates and error rates {#false-positives}

The **base rate** of a characteristic of interest is the probability of randomly selecting that specified characteristic from a relevant population. For example, in a population of 100 people 50 of whom have brown hair and 50 of whom have blonde hair, the base rate for brown hair is 0.5. The odds of brown:blonde hair are evens and so the prior odds of any one randomly selected individual having brown hair are evens. Base rates express prior probabilities/odds. In the context of diseases, the base rate is also known as the disease **prevalence**. 

**Error rates** are used to quantify the uncertainty in making incorrect or inaccurate decisions and their exact definition depends upon context. An important context in forensic science is the error rate of binary decision: classifying a result as positive/negative, inclusion/exclusion, etc. In this context, the error rate describes the probability of making an incorrect classification. Error rates inform likelihood ratios.

Errors for binary classifications are often known as false positives and false negatives. If the truth is that there is a negative case, and it is mistakenly labelled as a positive case, then the assignment is a **false positive**. If the truth is that there is a positive case, and it is mistakenly labelled as a negative case, then the assignment is a **false negative**. If the classification is correct, then the assignment was a **true positive** or **true negative**, respectively. This information is presented in Table \@ref(tab:intro-fp-table).

```{r intro-data, include=FALSE}
introDf <- tibble("Truth" = c("Positive", "Negative"),
                  "Labelled positive"=c("True positive",
                                        "False positive"),
                  "Labelled negative"=c("False negative",
                                        "True negative"))
```


```{r intro-fp-table, echo=FALSE}
options(kableExtra.html.bsTable = T)
introDf %>%
  mutate("Labelled positive" = cell_spec(
    `Labelled positive`, color = colPal[c(6, 7)], bold = T
  )) %>%
  mutate("Labelled negative" = cell_spec(
    `Labelled negative`, color = colPal[c(7, 6)], bold = T
  )) %>%
  knitr::kable(booktabs = TRUE, escape = F, align = "c",
             caption = 'Labelling statistics based on the assigned label and the underlying truth.') %>%
  kable_styling(c("striped", "condensed"), 
                latex_options = "striped")

```

If many assignments of positive/negative have been made under controlled conditions, e.g. when the underlying truth of positive or negative is known, then a reliable probability can be formed to determine the **rate** of true/false positives/negatives. These rates corresponds to the probability of each entry in Table \@ref(tab:intro-fp-table) occurring. The probability of a false positive occurring is called the **false positive rate** and the probability of a false negative occurring is called the **false negative rate**. The probability of a true positive occurring is called the **sensitivity** and the probability of a true negative occurring is called the **specificity**.

## Example: diagnostic tests {#exm-test}

The following example is adapted from @aitken2010. There is a disease in a population of 10,000 people and there is a test to diagnose the disease. The base rate and error rates have the following properties:

```{r test-data, include=FALSE}
testDf <- tibble("Disease" = c("Present",
                               "Absent",
                               "Total"),
                 "Test positive"=c(99, 495, 594),
                 "Test negative"=c(1, 9405, 9406),
                 "Total"=c(100, 9900, 10000))
```

* disease base rate: 0.1
  + meaning: the disease affects 100 people out of the total 10,000, and it does not affect the other 9,900.
* test sensitivity: 0.99
  + meaning: out of the 100 people who have the disease, 99 of them have a positive test result. The final 1 person tests negative despite having the disease. This person receives a false negative result.
* test specificity: 0.95
  + meaning: out of the 9,900 people who do not have the disease, 9,405 have a negative test. The other 495 people test positive despite not having the disease. These people receive false positive results.

This information is visualised in the tree diagram in Figure \@ref(fig:freq-tree-test).

<!-- This information is displayed in Table \@ref(tab:test-table). -->

<!-- ```{r test-table, echo=FALSE} -->
<!-- options(kableExtra.html.bsTable = T) -->
<!-- testDf %>% -->
<!--   mutate(Disease = cell_spec( -->
<!--     Disease, bold = T -->
<!--   )) %>% -->
<!--   knitr::kable(booktabs = TRUE, escape = F, align = "c", -->
<!--              caption = 'The number of people who are affected by the disease and their diagnostic test results.') %>% -->
<!--   kable_styling(c("striped", "condensed"),  -->
<!--                 latex_options = "striped") -->

<!-- ``` -->
```{r freq-tree-test, echo=FALSE,fig.cap="An expected frequency tree diagram of the disease testing example. Out of the 594 people who test positive (shown in bold font), 99 (~17%) have the disease. ", out.width = '80%', fig.align = 'center'}
e <- c(1, 2, 1, 3, 2, 4, 2, 5, 3, 6, 3, 7)
v <- c("10,000 \npeople", "100\ndisease", "9,900\nno disease", "99\npositive", "1\nnegative", "495\npositive", "9,405\nnegative")
fw <- c(1, 1, 1, 2, 1, 2, 1)
createBinaryTree(e,v,fw)
```

Out of the total 594 people who test positive, only 99 (~17%) are true positives. This means that if a randomly selected individual from this population tests positive, then it is highly likely that they do not have the disease. This phenomenon is caused by the very low **base rate** (prior probability/odds) of the disease. A randomly selected individual has a very low probability of having the disease prior to being tested and so even a test with low false positive rate will still lead to many false positives overall. This demonstrates why the base rate is an important factor to consider as well as error rates.

```{block eval=FALSE, include=isDynamicOutput()}
## Interactive disease testing

The example above made the point that the base rate was an important factor in determining the proportion of true positive tests. This effect is demonstrated in the interactive tool below. By changing the base rate from low to high and vice versa, you may compare the number of true positive tests to the number of false positive ones as a function of the base rate of the disease. If the plots are not displaying correctly, then please refresh your page.

```
```{r echo=FALSE}
if(isDynamicOutput()){
  knitr::include_app(getInteractiveLink("tabDiseaseTest", NULL, TRUE), height = '900px')
}
```

## Example: doping {#exm-doping}

The following example has been adapted from @statsprimer2020.

>A test designed to detect athletes who are doping is claimed to be '95% accurate'. If an athlete is doping then the test returns positive 95% of the time, and if the athlete is not doping then the test returns negative 95% of the time. It is suspected that around 1 in every 50 athletes dope. An athlete tests positive for doping using this test during a random drugs screening. How likely is it that they are really doping?

Technical diagnostic testing information often needs to be `translated' before it can be depicted clearly using a graphical representation. We can convert some of the above written information into the technical definitions. The second sentence states that the sensitivity and specificity are both 0.95, although the terms are not explicitly used. The base rate for doping is given as approximately 0.02.

Assume, for clarity, that we have a relevant population of 10,000 athletes. The technical information means the following:

* doping base rate: 0.02
  + meaning: we expect 200 athletes to be doping and 9,800 not to be doping.
* test sensitivity: 0.95
  + meaning: out of the expected 200 athletes who are doping, the test is expected to return positive for 190 of them and negative for 10 of them. We expect 10 false negatives. 
* test specificity: 0.95
  + meaning: out of the expected 9,800 athletes who are not doping, we expect 9,310 to test negative and 490 to test positive. We expect 490 false positives.

This is shown in the tree diagram format in Figure \@ref(fig:freq-tree-doping).

```{r freq-tree-doping, echo=FALSE,fig.cap="An expected frequency tree diagram of the doping example. Out of the 680 athletes who test positive (shown in bold font), 190 (~28%) are doping. ", out.width = '80%', fig.align = 'center'}
e <- c(1, 2, 1, 3, 2, 4, 2, 5, 3, 6, 3, 7)
v <- c("10,000 \nathletes", "200\ndoping", "9,800\nnot doping", "190\npositive", "10\nnegative", "490\npositive", "9,310\nnegative")
fw <- c(1, 1, 1, 2, 1, 2, 1)
createBinaryTree(e,v,fw)
```

The answer to the question is that given a positive test result, we expect the athlete to be doping roughly 28% of the time. This is another example of how a low base rate can result in a low posterior probability, even when the testing error is relatively low. 

```{block eval=FALSE, include=isDynamicOutput()}
## Interactive doping

Below is an interactive tool for the doping example. You can explore the effect of changing the test sensitivity and specificity on the number of false positives and false negatives that the test makes for a hypothetical population of athletes. Even for the maximum settings in the sliders for these test properties there are still only twice as many true positives as there are false positives. If the plots are not displaying correctly, then please refresh your page.

```
```{r echo=FALSE}
if(isDynamicOutput()){
  knitr::include_app(getInteractiveLink("tabDopingTest_probabilities","DopingTest",TRUE), height = '1100px')
}
```

```{block eval=FALSE, include=isDynamicOutput()}
## Summary: probability

Use the activity below to create a summary of the key points from this chapter.
```
``` {r probability-summary-questions, echo=FALSE}
if(isDynamicOutput()){
  knitr::include_url(paste0(QUESTIONS_HOST,"Probability-Summary.html"), height=800)
}
```

## More information

In this chapter on Probability we focussed on probability models and the expectations that a probability model forms for real events, e.g. a number of coin tosses. However, these expectations are often not exactly what is observed in practice, e.g. with real tosses of the coin. Analysing empirical events such as this moves from the field of probability to the field of statistics, and is currently outside the content of this book. If you would like to explore statistics for the coin toss examples presented in this chapter, then you may do so in the [interactive application](https://lrcfs.dundee.ac.uk/apps/interactive-lr/) which accompanies this book under the 'Coin Toss - Single Toss Samples' and 'Coin Toss - Double Toss Samples' tabs.

<!-- ## Research study -->

<!-- If you are taking part in our research study, please return to the survey now to answer the questions about this chapter. -->
