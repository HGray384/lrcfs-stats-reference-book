# Uncertainty {#uncertainty}

```{r package-load-uncertainty, include=FALSE}
source("./code/helper-functions.R")
# check and load the libraries
needPackages("igraph",
             "ggthemes",
             "kableExtra",
             "tidyverse",
             "plotly")
# set some useful variables
source("./code/useful-variables.R")
```

> "... in this world there is nothing certain but death and taxes."
>
> --- Benjamin Franklin

Benjamin Franklin wrote this in 1789 in the context of the newly formed US constitution. Inadvertantly, it is also a very helpful starting point to begin thinking about probability and statistics: by becoming familiar with uncertainty. 

The word uncertainty is used by many people in different contexts with a variety of intended meanings. It's useful to discuss what we mean by uncertainty, provide some examples of situations in which it is useful to think about and communicate uncertainty, and to highlight its role in evaluating forensic scientific evidence. That's what we'll do in this Chapter.

## The impact of uncertainty

Uncertainty describes a situation in which we do not know something. Since we cannot know everything, uncertainty is unavoidable. 

Uncertainty can lead to nice surprises and make life more exciting. But unfortunately, it can also make things very uncomfortable. Not knowing if bad things will happen and what effects they might have can be stressful. Managing and communicating uncertainty can help to mitigate possible negative consequences. The communication part is key to forming expectations and adjusting existing expectations to be more realistic. However, in many aspects of life today, uncertainty is simply ignored or it is deliberately hidden from those who can benefit from knowing it. 

The COVID-19 pandemic has been another reminder to us that medical diagnostic test results can be wrong, that viruses do not always produce the same (or any) symptoms, and that official statistics do not count everything we might think they would. These things are uncertain and that's not always made clear. It has been demonstrated on a daily basis recently that understanding and communicating uncertainty has significant consequences when handling a public health emergency. 

The justice system has also been challenged by uncertainty during this time: how to continue administering justice and what the justice process will look like in the future. Challenges arising from uncertainty in the pre-pandemic era also remain. Imprisoned individuals are still being exonerated (notably in the US) after overly confident expert testimony is revisited. The impact of uncertainty is clear and very serious. 

In society there are many situations in which we can better handle uncertainty. This will come with building a better understanding of uncertainty and having honest and open discussions about it. We aim to contribute to that in forensic science, by framing evidence evaluation around uncertainty. To start things off, we can make a distinction between different types of uncertainty.

## Types of uncertainty

Uncertainty in its broad definition from the previous section covers a spectrum of situations. Some of these situations can seem fundamentally different based upon the type of uncertainty they express. We focus on two types of uncertainty

1. **Aleatory uncertainty**: uncertainty due to variation. 
2. **Epistemic uncertainty**: uncertainty due to ignorance.

**Aleatory uncertainty** concerns situations with natural variability, sometimes referred to as **chance**. With this type of uncertainty, we cannot be certain about something because there is a component of randomness to it. By way of example, before I spin a roulette wheel, I ask you what number the ball will land on. Due to the randomness involved in the spin, you cannot know the outcome and so your guess will be uncertain. We cannot reduce this uncertainty because it is inherent in the process that causes it.

**Epistemic uncertainty** concerns situations about which we have a lack of knowledge. The reason for this type of uncertainty is that we do not know all of the necessary information. Suppose I ask you to turn your back so that you do not see the result of the roulette spin. I spin the wheel and see the result, and then I ask you to guess the number. Your guess is now uncertain not because of randomness, but because you do not have the information that I have. There is no uncertainty for me but there is for you, and your uncertainty can be eliminated by learning what I know. We can reduce this uncertainty by obtaining more information.

This idea of personal uncertainty is key when thinking about events which have happened in the past. It is clearly true that past events have either occurred or not. Some people hold the belief that there cannot be uncertainty about past events because of this. An alternative perspective is to consider uncertainty as being personal to an individual. Instead of asking "uncertainty about what?", ask "uncertainty to whom about what?" If uncertainty is personal, then anyone who does not have much information about a past event can have a reasonable amount of uncertainty about its truth.

This uncertainty is reflected in the phrase 'beyond reasonable doubt', the burden of proof for the prosecution in UK criminal trials. It is not 'without any doubt'; there is room for some uncertainty. Events have happened but maybe only the aggrieved and the defendant are certain about the truth. The fact finder begins a trial with a high degree of uncertainty about events, with the presumption of innocence on behalf of the defendant. Evidence which shines light on the truth is presented to the fact finder in an attempt to reduce this epistemic uncertainty about events. Upon hearing all the evidence, the fact finder makes a decision as to whether the prosecution sufficiently reduced their uncertainty to 'beyond reasonable doubt' in favour of guilt. 

Uncertainty is present in all parts of the legal system as it is in every other aspect of society. Now that we have discussed the types of uncertainty, we can hone in on how it manifests in scientific evidence.

## Uncertainty in scientific evidence

There are multiple sources of aleatory and epistemic uncertainty in forensic scientific evidence. The reliability in the underlying science and the application of the science varies across the different scientific evidence types. This means that the uncertainties will be different depending on the type of evidence in question. In this section, we will consider evidence in general and the collective uncertainties that can be present. Then we work through a small example using a specific instance of fibre evidence.

We will consider the following questions when thinking about uncertainty in forensic scientific evidence:

1. What are we uncertain about? 
2. What are the sources of uncertainty? 
3. What is the level of our uncertainty? 
4. What is the magnitude of uncertainty? 
5. In what form is the uncertainty communicated? 

Let's take a look at each of these in the order that they appear above.

**What are we uncertain about?** This is the **object** of uncertainty. This is most often the sequence of events which led to the evidence. Nested within this, there can also be uncertainties about the characteristics of the evidence, the analysis of the evidence, comparisons of the evidence to information within databases, expert opinion concerning the evidence, etc.

**What are the sources of uncertainty?** These are the **reasons** for uncertainty. Imprecise measurements, contaminated evidence, lack of scientific knowledge, database limitations, subjective interpretation, etc.

**What is the level of our uncertainty?** This is whether each uncertainty relates **directly** to the object itself or **indirectly** through uncertainties about things which affect the object. For example, uncertainty about the item of evidence is direct but lack of confidence in the science underlying the evidence interpretation is indirect.

**What is the magnitude of uncertainty?** This is **how** uncertain we are. Does the measurement technology have a high or low level of precision? Is the database highly reliable or not? Is the expert's interpretation generally reasonable or is it radical? How well does the evidence support the prosecution?

**In what form is the uncertainty communicated?** What tools are used to **communicate** the uncertainty to others. Is uncertainty mentioned in the expert report? Is it clear that uncertainties have been addressed or are they only acknowledged? Has a number been used to convey the uncertainty, or a verbal expression?

## Example: fibre evidence

Let's think about an example of fibre evidence found at a crime scene. In this case we'll assume that fibres matching clothing of the suspect were recovered at the scene. The main uncertainty is whether or not the suspect committed the crime. This is epistemic uncertainty: the suspect either did or did not commit the crime but we don't know which is true. The fibre evidence alone might not completely reduce this uncertainty, but it could reduce it somewhat by reducing uncertainty about whether or not the suspect was at the crime scene. 

The expert who interprets the fibre evidence addresses uncertainty about the evidence. The fibre evidence is the **object** of uncertainty in this example. The **reasons** for uncertainty about this evidence might relate to how rare this type of fibre is in the general population or how well it transfers from clothing to surfaces and how well it persists on those surfaces. These are **direct** uncertainties about the fibre evidence.

Claims about these direct uncertainties will often be supported by scientific studies, e.g. databases containing the frequency of certain fibres, which may be informed by other recovered clothing of a similar type or population surveys. Uncertainties about the fibre evidence which relate to the reliability of the database in this specific case circumstance or the underlying survey methodology are **indirect**. 

The expert will synthesise these uncertainties either quantitatively using a mathematical model or qualitatively using their expertise (for which there is more uncertainty about the appropriateness of the mathematical model or the calibration of expert opinion). The result will be a number or a range of possible numbers describing the **magnitude** of a particular uncertainty. For example, the expert might determine that out of every 1000 similar case circumstances they would expect 200 to yield a fibre match if the suspect had truly been at the crime scene. The expert might also determine that out of every 1000 similar case circumstances they would expect only 2 to yield a fibre match if the suspect had truly not been at the crime scene.

It is recommended practice that these magnitudes of uncertainty are combined into a single quantity, known as the likelihood ratio. This quantity is then **communicated** in expert reports. In the fibre example, the expert has determined that it is 100 times more likely that the fibre evidence would have been observed if the suspect had been at the crime scene rather than if they hadn't. All of the content in this book builds up to understanding likelihood ratios, and we circle back to them at the end in Chapter \@ref(likelihood-ratio). 

In the example above, we only focussed on one possible object of uncertainty. In reality, there are dozons of these objects that the expert has to consider and combine when interpreting evidence. The reasons for each of these objects of uncertainty will be case dependent and most often complicated by the complicated nature of criminal activities. This makes assessing uncertainty challenging. The expert might reasonably ignore some uncertainties to make this task more feasible.

In addition, the 'science' part of forensic science is still a developing field. Expert interpretations which historically overlooked (and in some cases ignored) major elements of uncertainty in their discipline are gradually being updated by practices which are informed by scientific evidence. But have no illusion, there is still a long way to go. There is still a large amount of epistemic uncertainty. Notwithstanding this, there will always be a degree of aleatoric uncertainty due to the probabilistic nature of real-world processes, e.g. transference of materials from direct contact with surfaces (and many others). One result of this at (pre-)trial is that there might always be reasonable disagreement between experts. These disagreements can still be settled in the mind of the fact finder in the same way as disagreements in other aspects of evidence: through cross-examination.

Uncertainty in both of its forms is (and will always be) an integral part of scientific evidence. This means that it is important for us as a community to work together to ensure a common understanding of uncertainty, both in terms of how we think about it and how we talk about it. A lot of research thus far has focussed on how we should think about uncertainty. There is still more work to be done on talking about uncertainty in scientific evidence, especially when results need to be conveyed to non-experts. This brings us on to the final section of this chapter.

## Communicating uncertainty

Despite uncertainty being everywhere, the communication surrounding it (particularly by experts) leaves much room for improvement. One reason for this is because communicating uncertainty is hard. There are some barriers which make it hard, and these barriers can prevent experts from communicating it well. Some of the barriers include the following:

- The exact meaning of uncertainty can be uncertain. As explained before, the word uncertainty means different things to people in the first place.

- It is hard to explain uncertainty in a way that is understandable. It often deals with thinking about hypothetical events in the future or past and considering hypothetical or real outcomes of those hypothetical events. This requires creativity and experience to get right, and even then it's easy to make mistakes. Understanding and switching between quantitative forms of uncertainty requires a high level of numeracy and lots of practice.

- It is hard to know which uncertainties to communicate, and which to spare the detail of. The uncertainties need to be relevant to the receiver but at the same time not overlook important detail. What is 'relevant' and which details are too 'important' to omit is context-specific.

- It is challenging to communicate uncertainty when in a position of trust. There is a perception among experts that expressing uncertainty diminishes trust and credibility. Fortunately, there is growing evidence to suggest that the opposite is true when communication is done well. 

- It is hard to communicate uncertainty to a decision-maker. From the receiver's perspective, they may want a definite answer so that their decision is easier. The communicator may also want to facilitate this. However, overlooking uncertainty removes agency from the receiver in their capacity to make their own decision. Moreover, ignoring uncertainty means that they will not be fully informed. 

When these barriers are overcome and uncertainty is communicated, then it can come in a variety of formats.

For direct uncertainties, this can range from having a full and explicit distribution of possible outcomes along with quantified uncertainties associated to each outcome, to an overt denial that any uncertainty even exists (this is communicating uncertainty by saying that there is no uncertainty). Statements can be absolute or relative, e.g. very likely versus more likely than.

Indirect uncertainties are usually presented as a subjective verbal statement about the quality of the underlying evidence. A number of systematic approaches have been developed to make this subjective judgement more consistent and transparent. They tend to define checklists of characteristics which then determine a category for evidence quality based on how many criteria on the checklist the evidence meets. For example, the GRADE scale has been developed to assess the effects of medical interventions. It has categories which range from 'very low quality' to 'high quality', and presents this graphically.

The endorsed approach when evaluating forensic scientific evidence is to quantify direct uncertainty about specific evidence related to a contested event and then to present that as a number, range of numbers, or to translate a number into a verbal qualifying statement. The resulting statement is always relative, in that it gives the fact finder information about the scientific evidence in light of the prosecution versus the defence's assertions. Indirect uncertainties are usually given as a subjective verbal statement, or a factual statement describing the strengths and weaknesses of the quality of the evidence. No systematic approach is currently used for assessing and communicating indirect uncertainties.

Since quantifying uncertainty plays an important role in evaluating forensic scientific evidence, it is important that we are speaking the same language when it comes to communicating about it. The common numerical language for uncertainty is probability, and this is what we look at in the next chapter. 

## More information

GRADE: https://www.gradeworkinggroup.org/

## Exercises
