# Uncertainty {#uncertainty}

```{r package-load-uncertainty, include=FALSE}
source("./code/helper-functions.R")
# check and load the libraries
library("igraph")
library("ggthemes")
library("gdtools")
library("kableExtra")
library("tidyverse")
library("plotly")
# set some useful variables
source("./code/useful-variables.R")
```

In 2008, Kennedy Brewer was exonerated after 15 years in prison for the brutal murder of his then-girlfriend's 3 year old child. Expert testimony had claimed that marks found on the body of the child had been bite marks and had without a doubt been caused by Brewer. The expert's belief did not accurately reflect the uncertainty in the scientific understanding of bite mark evidence. 

Becoming familiar with uncertainty is the basis for thinking about probability and statistics, and ultimately evaluating scientific evidence. In this chapter, we will define what is meant by uncertainty, how different types of uncertainty can be characterised, give an example of uncertainty in scientific evidence, and finally discuss the communication of uncertainty. 

## What we mean by *uncertainty*

In this book, we frame discussions about uncertainty around beliefs, since beliefs about facts are the focus of forensic science. Certainty describes a belief which can be guaranteed without any doubt. If there is any doubt in the belief then it cannot be called certain. We call those beliefs uncertain. Beliefs can have varying degrees of doubt and so uncertainty can be described on a spectrum with one end containing beliefs with high degrees of uncertainty and the other containing beliefs with low degrees of uncertainty. Many beliefs come with at least some degree of doubt, however small it may be, and so must be uncertain. This makes uncertainty unavoidable. 

Communicating uncertainty is key to forming and calibrating realistic expectations. When uncertainty is communicated well and everyone has realistic expectations then it can be managed effectively in order to mitigate negative consequences. However, in practice there are understandable incentives against doing this. One example is that people in positions of authority (such as politicians) do not want to diminish the trust of those they have a responsibility towards by admitting that they do not know something. Another is when the uncertainty might cause a disproportionately negative reaction, e.g. uncertainty about nuclear war. This means that unfortunately, in many aspects of life, uncertainty is simply ignored or concealed. 

<!-- One of the many uncertainties during the COVID-19 pandemic during 2020 has been medical diagnostic testing. Results from medical tests which aim to diagnose disease are usually uncertain. Tests can return positive results for people who do not have the disease in question, known as false positive results, and tests can also return negative for those who do have the disease in question, known as false negative results. This means that for any group of people who are all tested, the number of positive tests may not accurately reflect the number of people who have the disease. Even highly reliable tests will result in many false results provided that enough people are tested. This is a problem for diseases that are not well understood and this is emphasised when using tests which are new and not yet fully validated. The resulting situation of a new disease with new tests is highly uncertain.  -->

In society, there are many situations in which we can communicate and manage uncertainty better. This will come with building a better understanding of uncertainty and having honest and open discussions about it. We aim to contribute to that in forensic science, by framing scientific evidence evaluation around the fact that it is uncertain. In order to do this, it is useful to be more specific about different types of uncertainty.

## Types of uncertainty

Uncertainty in its broad definition from the previous section covers a spectrum of situations. There can be clear logical differences between uncertain beliefs based upon the type of uncertainty that is described. We focus on two types of uncertainty:

1. **Aleatory uncertainty**: uncertainty due to variation. 
2. **Epistemic uncertainty**: uncertainty due to a lack of knowledge.

**Aleatory uncertainty** describes situations with natural variability, sometimes referred to as **chance**. With this type of uncertainty, we cannot be certain about something because there is a component of randomness to it. For example, before a roulette wheel is spun, you are asked what number the ball will land on. Assuming the spin is not fixed to favour any particular number, then the result will be random in the sense that there is no strategy that is guaranteed to win more often than selecting a number at random. Due to the randomness involved in the spin, your guess will be uncertain. This type of uncertainty cannot be reduced because it is inherent to the process that causes it.

**Epistemic uncertainty** concerns situations about which we have a lack of knowledge. The reason for this type of uncertainty is that we do not know all of the necessary information. Suppose I ask you to turn your back so that you do not see the result of the roulette spin. I spin the wheel and see the result, and then I ask you to guess the number. Your guess is now uncertain not because of randomness, but because you do not have the information that I have. There is no uncertainty for me but there is for you, and your uncertainty could be eliminated by learning what I know. Epistemic uncertainty can be reduced by obtaining more information.

The idea of uncertainty being personal is key to thinking about events which have happened in the past. Past events have either occurred or not, and so they are factually certain. However, an individual's beliefs about those past events can be epistemically uncertain because they have insufficient information. Individuals will base their beliefs on the information that they have available to them and, since this information and how it is valued could vary from person to person, it is possible to have varying degrees of epistemic uncertainty between individuals about the same factually certain event. Imagine that another player is introduced into the roulette example above. I ask you both to turn your back whilst I spin the wheel and I see that the result is a 10. I then tell you nothing about the result but I tell the new player that the result is an even number. You still have the same uncertainty as before but the new player has less uncertainty than you because they have more knowledge about the result; you both have different degrees of epistemic uncertainty about the same factual event. 

Epistemic uncertainty is reflected in the courts through the phrase 'beyond reasonable doubt', the burden of proof for the prosecution in UK criminal trials. It is not 'without any doubt'; there is room for some uncertainty about the facts. Events have factually occurred but perhaps only the aggrieved and/or the defendant are certain about the truth. On the other hand, the fact finder begins a trial with a high degree of uncertainty about events with the presumption of innocence on behalf of the defendant. Evidence about the facts is presented to the fact finder in an attempt to reduce their epistemic uncertainty. Upon hearing all of the evidence, the fact finder makes a decision as to whether the prosecution sufficiently reduced their uncertainty to 'beyond reasonable doubt' in favour of guilt. When the fact finder is a jury, then each juror must have their personal epistemic uncertainty reduced to this level during the initial stage of deliberation. 

Uncertainty is present in all parts of the legal system as it is in every other aspect of society. This includes uncertainty in scientific evidence.

## Uncertainty in scientific evidence {#uncertainty-model}

There are multiple sources of aleatory and epistemic uncertainty in forensic scientific evidence. As well as the unique uncertainties that arise from individual case scenarios, there are generic uncertainties which relate to the collection, analysis, and interpretation of different scientific evidence types. Some of these generic uncertainties are shared across evidence types, for example the transfer and persistence of materials on surfaces, whilst others are specific to a particular evidence type, such as the analysis of low template or mixture DNA evidence. Here we consider general uncertainties of the forensic scientist and how they can be approached.

Consider the following questions when thinking about uncertainty in forensic scientific evidence:

1. What are we uncertain about? 
2. What are the sources of uncertainty? 
3. What is the level of our uncertainty? 
4. What is the magnitude of uncertainty? 
5. In what form is the uncertainty communicated? 

These questions follow the model of communicating uncertainty presented in @vanderbles2019 and we will apply this model to forensic evidence.

**What are we uncertain about?** This is the **object** of uncertainty. This is commonly the sequence of events which led to the evidence. Nested within this, there can also be other objects such as the characteristics of the evidence, the analysis of the evidence, comparisons of the evidence to information within databases, expert opinion concerning the evidence, etc.

**What are the sources of uncertainty?** These are the **reasons** for uncertainty. Imprecise measurements, contaminated evidence, lack of scientific knowledge, database limitations, subjective interpretation, etc.

These first two questions make it clear exactly what we are uncertain about and why. In an expert witness report, they can appear as the rationale behind what the expert has been tasked to do and why they have done it.

**What is the level of our uncertainty?** This is whether the uncertainty relates **directly** to the object itself or **indirectly** through uncertainties about things which affect the object. For example, uncertainty about an item of evidence is direct but lack of confidence in the science underlying the evidence interpretation is indirect.

This particular question is important because these two levels of uncertainty can be evaluated differently. Direct uncertainty is often easier to quantify than indirect uncertainty, which will be explained in more detail in the next chapter. In practice, this means that in expert witness reports it is easier to treat direct uncertainties with an evaluative likelihood ratio approach than it is for indirect uncertainties. Indirect uncertainties may be listed in the expert's report as a verbal caveat for the expert's evaluation or may have contributed to a decision not to evaluate the evidence using a likelihood ratio approach. 

**What is the magnitude of uncertainty?** This is the extent or size of **how** uncertain we are. Does the measurement technology have a high or low level of precision? Is the database highly reliable or not? Is the expert's interpretation more or less reasonable compared to other experts in their field? How well does the evidence support the prosecution?

**In what form is the uncertainty communicated?** What tools are used to **communicate** the uncertainty to others. Is uncertainty mentioned in the expert report? Is it clear that uncertainties have been addressed or are they only acknowledged? Has a number been used to convey the uncertainty, or a verbal expression?

The final two questions above are examples of evaluating and communicating uncertainty. In expert witness reports, this is where the expert presents their evaluative opinion having considered the evidence alongside the case circumstances and hypotheses put forth by legal counsel. If they have used a likelihood ratio approach, then this evaluation will be given on a numerical or verbal scale (in the UK). For certain types of evidence such as fingerprint identification, the expert may give their opinion as the inclusion or exclusion of an individual. 

Forensic science is a continuously developing field. Expert interpretations which historically overlooked (and in some cases ignored) major elements of uncertainty in their discipline have been and continue to be updated by practices which are informed by scientific evidence. However, there is still a long way to go in some fields e.g. understanding transfer and persistence of fibres.

There will always be aleatory uncertainty due to the random nature of real-world processes and epistemic uncertainty due to the limitations of our knowledge. This explains reasonable disagreement between experts in which personal uncertainties may diverge. These disagreements can still be settled in the mind of the fact finder in the same way as disagreements in other aspects of evidence: through cross-examination.

## Example: fibre interpretation

Fibre interpretation is a term used for interpreting forensic findings related to textile fibres which are shed from textile materials (such as an item of clothing) as a result of contact with another textile material or surface.

Fibres can be transferred via direct and indirect contact. Direct contact means that the transfer was caused by physical contact between a textile material which sheds the fibre and a surface on which the fibre is found. Indirect contact means that the transfer occurred despite there being no physical contact between the textile material which shed the fibre and the surface on which the fibre is found. This can happen when fibres are transferred in a chain of one or more direct contacts with other surfaces so that the start and end materials in the chain never have direct contact with each other. 

Fibres that are recovered from a surface or textile material of interest to an investigation, known as **questioned samples**, can be compared to fibres which are taken from a suspected textile material of origin, known as **reference samples**. The comparison aims to distinguish between the questioned and reference samples using properties of the fibres such as their material, size, shape, and colour. 

Fibres can be useful for forensic interpretation because they can help to discriminate between hypotheses of physical contact between persons of interest in an investigation. They give the fact finder information about a possible activity having taken place perhaps in a specific location.

In this example, we consider some generic uncertainties encountered by a fibre examiner when interpreting the implications of recovered (or absent) fibres. After a suspect has been identified and taken to trial, the primary uncertainty for the court to consider is whether or not the suspect committed the crime in question. This is epistemic uncertainty: the suspect either did or did not commit the crime but the fact finder does not know which is true prior to seeing evidence (although innocence is presumed). Depending on the case circumstances, the expert's fibre interpretation alone will likely not be sufficient to reduce the fact finder's uncertainty about whether the suspect committed the crime or not. However, it may be helpful in reducing the fact finder's uncertainty about other related hypotheses, for example, whether or not the suspect was present at the crime scene. This could be useful for the fact finder to combine with other evidence. 

Suppose that the expert is tasked with interpreting fibres recovered from the suspect's clothing (the reference sample) and fibres recovered from the crime scene (the questioned sample). There are many potential objects of uncertainty for the fibre examiner to address in this general situation, and in practice the examiner is usually directed as to which objects of uncertainty to address. In this example, we select the **object** of uncertainty to be whether or not the suspect was at the crime scene. This is an example of epistemic uncertainty. 

- **Object** of uncertainty: whether or not the suspect was at the crime scene.
- **Reason** for uncertainty:
  + two credible alternative events presented by prosecution and defence,
  + variability in fibre recovery, transfer, and persistence,
  + limited relevant scientific studies.
- **Level** of uncertainty for each of the above reasons:
  + direct,
  + direct,
  + indirect.
- **Magnitude** of uncertainty: the expert can take into account relevant case circumstances as well as what is known about the variability in fibre recovery, transfer, and persistence to determine, for example, that
  + out of every 1000 similar case circumstances they would expect 200 of them to yield the questioned sample of fibres if the suspect had truly been at the crime scene,
  + out of every 1000 similar case circumstances they would expect only 2 to yield the questioned sample of fibres if the suspect had truly not been at the crime scene,
  + limited relevant scientific studies present uncertainty that is difficult to quantify.
- **Communication** of uncertainty: the expert can compare the quantified uncertainty and caveat the qualitative uncertainty to state that
  + it is 100 times more likely (200 out of 1000 times compared to 2 out of 1000 times) that the fibre evidence would have been observed if the suspect had been at the crime scene rather than if they had not,
  + there are limitations to the available scientific studies, and state them.

<!-- The **reasons** for this uncertainty have multiple sources.  -->

<!-- might relate to credible alternative events put forth by the prosecution and defence, another example of epistemic uncertainty. There could also be aleatory uncertainty because the same textile material will shed a variable number of fibres even for the same type of contact under the same amount of pressure. These are **direct** uncertainties about the fibre evidence. -->

<!-- Claims about these direct uncertainties will often be supported by other available information. This can include population surveys about the occurrence of textiles in a particular location, or scientific studies examining the shedability of fibres after controlled levels of contact. Uncertainties about the reliability of the scientific methodology underlying this supporting information, or its applicability to a particular case circumstance are **indirect**, e.g. doubts as to how applicable a fibre survey from Beijing, China is to a case in Dundee, Scotland. -->

<!-- The expert will synthesise their uncertainty either quantitatively using a mathematical model or qualitatively using their expertise (for which there is more uncertainty about the appropriateness of the mathematical model or the calibration of the expert's opinion). The result might be a number, a range of possible numbers, or qualitative verbal statements, all of which describe the **magnitude** of a particular uncertainty. For example, the expert might determine that out of every 1000 similar case circumstances they would expect 200 of them to yield the questioned sample of fibres if the suspect had truly been at the crime scene. The expert might also determine that out of every 1000 similar case circumstances they would expect only 2 to yield the questioned sample of fibres if the suspect had truly not been at the crime scene. -->

<!-- It is recommended practice that these magnitudes of uncertainty (when quantified) are combined into a single quantity, known as the likelihood ratio. This quantity is then **communicated** in expert reports. In this example, the expert has determined that it is 100 times more likely (200 out of 1000 times compared to 2 out of 1000 times) that the fibre evidence would have been observed if the suspect had been at the crime scene rather than if they had not.  -->

The fact finder can use this communication, as well as other evidence, to make a decision as to whether they believe the suspect was at the crime scene or not.

In the example above, we only focussed on one possible object of uncertainty. In reality, there are many more objects that the expert has to consider and combine when interpreting forensic findings. The reasons for uncertainty for each of these objects will be case-dependent and this is further complicated by the complex nature of real-life criminal activities. This makes assessing uncertainty challenging. The expert might reasonably ignore some uncertainties to make this task more feasible. Many possible uncertainties can be excluded by only considering the sequence of events put forth by the prosecution and defence.

```{block eval=FALSE, include=isDynamicOutput()}
## Drag and Drop: uncertainty
```
``` {r uncertainty-questions, echo=FALSE}
if(isDynamicOutput()){
  knitr::include_url(paste0(QUESTIONS_HOST,"Uncertainty-Examples.html"), height=600)
}
```

## Communicating uncertainty

Accurately communicating uncertainty in forensic science is crucial in order for the fact finder to fully assess the evidence. There is consensus from the UK Forensic Science Regulator and ENFSI that a likelihood ratio, range of likelihood ratios, or an equivalent verbal statement should be used to communicate direct uncertainties about the evidence. Examples include: 

- single number: the recovered number of indistinguishable fibres provide 50 times more support for the hypothesis that the questioned activity took place in the living room compared to the bedroom. 

- range of numbers: the recovered number of indistinguishable fibres provide between 10 to 100 times more support for the hypothesis that the questioned activity took place in the living room compared to the bedroom.

- verbal qualifier: the recovered number of indistinguishable fibres provide moderate support for the hypothesis that the questioned activity took place in the living room compared to the bedroom.

The resulting statement is always relative, in that it gives the fact finder information about the scientific evidence in light of the prosecution's assertions versus those of the defence. 

Indirect uncertainties in forensic evidence are usually given as a subjective verbal statement, or a factual statement describing the strengths and weaknesses of the quality of the evidence. No systematic approach is currently used for assessing and communicating indirect uncertainties. In the medical field, the [GRADE](https://www.gradeworkinggroup.org/) scale is routinely used to assess the effects of medical interventions. It has categories which range from 'very low quality' to 'high quality' depending on how the evidence compares against a standardised set of characteristics.

<!-- In other fields, a number of systematic approaches have been developed to make this subjective judgement more consistent and transparent. One way to achieve this is by defining a checklist of characteristics which determine a category for the quality of evidence based upon how many items on the checklist the evidence meets. For example, the [GRADE](https://www.gradeworkinggroup.org/) scale is routinely used to assess the effects of medical interventions. It has categories which range from 'very low quality' to 'high quality' depending on characteristics of the evidence. This may be a blueprint for forensic science to follow to systematically communicate indirect uncertainties in forensic evidence. -->

Assessing and communicating uncertainty plays an important role in evaluating forensic evidence. It is important to use a standardised framework for this so that any assumptions and conclusions that are made are clear and assessable for the court. The mathematical tool of probability theory provides this framework and ensures a common language for logical inference and is the focus of the next chapter. 

<!-- Since assessing uncertainty plays an important role in evaluating forensic scientific evidence, it is important that there is common ground when it comes to communicating it. This can be achieved through using a standardised framework for assessing uncertainty that is logically coherent. One example of coherence in this context can be making sure that inferences made using uncertainties are consistent and obey transparent logical rules. This means that inferences made within the standardised framework are logical, can be accurately described to others, and are able to be assessed by others - all of which are important for communication. These desirable properties (as well as others) are contained within the mathematical language of probability, and that is why it is used as a common means to handle uncertainty. The main utility of probability is not because it quantifies uncertainty, but because it is a complete and common framework for logical inference. Probability is the focus of the next chapter.  -->

```{block eval=FALSE, include=isDynamicOutput()}
## Summary: uncertainty

Use the activity below to create a summary of the key points from this chapter.
```
``` {r uncertainty-summary-questions, echo=FALSE}
if(isDynamicOutput()){
  knitr::include_url(paste0(QUESTIONS_HOST,"Uncertainty-Summary.html"), height=800)
}
```

<!-- ## Research study -->

<!-- If you are taking part in our research study, please return to the survey now to answer the questions about this chapter. -->
