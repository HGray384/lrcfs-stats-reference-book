# Likelihood ratio as value of evidence {#likelihood-ratio}

```{r package-load-likelihood-ratio, include=FALSE}
source("./code/helper-functions.R")
# check and load the libraries
needPackages("igraph",
              "ggthemes",
              "kableExtra",
              "tidyverse")
# set some useful variables
source("./code/useful-variables.R")
```

This Chapter introduces the likelihood ratio

## Relative support for competing propositions

Suppose that we have two competing propositions, A and B, as in the previous chapter. We observe an event E, and wish to know whether E was more likely assuming A or B. If E is more likely assuming A was true, then we say that E provides more support for A than B, and vice versa if E is more likely assuming B to be true. The likelihood ratio (LR) quantifies this support.

The LR consists of the probability of observing E conditioned on A being true, divided by the probability of observing E conditioned on B being true. As a formula it is written as
$$\text{LR}=\frac{\text{probability of E assuming A is true}}{\text{probability of E assuming B is true}}.$$

The trick here is that by assuming each proposition to be true in turn, we can see how much more likely E was to occur in A's version of events compared to B's.

Since each term in the LR is a probability, their value must lie between 0 and 1. This means that the LR itself must be between 0 and $\infty$. Values of the LR which are greater than 1 indicate relative support for A compared to B, since it means that the probability of E assuming that A is true is greater than the probability of E assuming B is true. Values of the LR which are less than 1 indicate relative support for B compared to A, since it means that the probability of E assuming that B is true is greater than the probability of E assuming A is true. Values of the LR which are equal to 1 indicate that E provides equal support for A and B when compared to each other. This is shown in Table \@ref(tab:lr-meaning-table).

```{r lr-meaning-df, include=FALSE}
lrDf <- tibble("LR" = c("less than 1",
                        "equal to 1",
                        "greater than 1"),
                  "Meaning"=c("More support for B compared to A",
                              "Equal support for both when compared to each other",
                              "More support for A compared to B"))
```

```{r lr-meaning-table, echo=FALSE}
options(kableExtra.html.bsTable = T)
lrDf %>%
  knitr::kable(booktabs = TRUE, escape = F, align = "c",
             caption = 'Meaning of values of the LR for event E.') %>%
  kable_styling(c("striped", "condensed"), 
                latex_options = "striped")
```

## Strength of support

The magnitude of the LR conveys the strength of the support which E provides for A or B when compared to each other. LRs of 1,000,000 and 10 both provide support for proposition A compared to B, but the LR of 1,000,000 provides much stronger support than the LR of 10 does. Similarly, LRs of 0.0000001 and 0.1 provide support for proposition B compared to A, but the LR of 0.0000001 provides much stronger support than the LR of 0.1 does. As the value of the LR gets further away from 1, the stronger the support is for proposition A or B (depending on whether the LR is greater or less than 1) when compared to its competitor.

One method to convey the numerical strength of an LR is to place it into a category of verbal expressions based on its numerical magnitude. Multiple suggested categorisations exist, such as the example given below in Table \@ref(tab:verbal-scale-table).

```{r verbal-scale-df, include=FALSE}
strength <- c("weak",
              "moderate",
              "moderately strong",
              "strong",
              "very strong",
              "extremely strong")
strengthSup <- paste(strength, "support")
props <- c("for A compared to B",
           "for B compared to A")
verbExpr <- c(paste(rev(strengthSup), props[2]),
              "equal support for A and B",
              paste(strengthSup, props[1]))
lrRange <- c("less than 0.000001",
             "at least 0.000001 but less than 0.0001",
             "at least 0.0001 but less than 0.001",
             "at least 0.001 but less than 0.01",
             "at least 0.01 but less than 0.1",
             "at least 0.1 but less than 1",
             "1",
             "at least 1 but less than 10",
             "at least 10 but less than 100",
             "at least 100 but less than 1000",
             "at least 1000 but less than 10,000",
             "at least 10,000 but less than 1,000,000",
             "at least 1,000,000")
vsDf <- dplyr::tibble("LR"=lrRange, "verbal expression"=verbExpr)
```


```{r verbal-scale-table, echo=FALSE}
options(kableExtra.html.bsTable = T)
vsDf %>%
  knitr::kable(booktabs = TRUE, escape = F, align = "c",
             caption = 'Verbal expressions to convey the strength of numerical LRs.') %>%
  kable_styling(c("striped", "condensed"), 
                latex_options = "striped")


```

The LR is determined by the values of the conditional probabilities which underly it. Figure \@ref(fig:lr-function) shows how the value of the LR changes based on the values of these probabilities.

```{r lr-function, echo=FALSE, fig.cap="LR values as its underlying probabilities vary. Values are coloured by their support for either proposition: blue is support for A compared to B, and orange is support for B compared to A. White is equal support for both.", out.width = '80%', fig.align = 'center'}
gridVals <- 101
prob1 <- prob2 <- seq(0, 1, length.out = gridVals)[-1]
vars <- expand.grid(prob1, prob2)
lrDf <- tibble(prob1 = vars$Var1, prob2 = vars$Var2)%>%
  mutate(lr = prob1/prob2)

ggplot(lrDf, aes(x=prob2, y=prob1, fill=lr)) +
  geom_tile() +
  xlab("probability of E assuming B is true") +
  ylab("probability of E assuming A is true") +
  scale_x_continuous(expand = c(0, 0)) +
  scale_y_continuous(expand = c(0, 0)) +
  scale_fill_gradientn(colors = c(colPal[7],
                                  colPal[2],
                                  "white",
                                  colPal[3],
                                  colPal[6]),
                       breaks = c(0.01, 0.1,
                                  1,10, 100),
                       labels=c(0.01, 0.1,
                                  1,10, 100),
                       name="LR", trans = "log"
                       # values = c(0, 0.4, 
                       #            0.5, 
                       #            0.6, 1)
  )
```

Figure \@ref(fig:lr-function) highlights some important properties of the LR:

- LR values close to 1 tell us nothing about the values of their conditional probabilities other than that they are roughly equal. So long as the probabilities are similar in size, extremely unlikely situations will be assigned the same LR as absolutely certain ones. This can be seen by the white strip across the diagonal of the figure.
- Most values for the probabilities lead to LRs which are no more than "moderate support" for either proposition in light of Table \@ref(tab:verbal-scale-table). This is the consequence of the probabilities being less than 1; if the probability of E conditioned on B is 0.25, then we know the LR can have a maximum value 4, since the probability of E conditioned on A is at most 1.
- Following on from the previous point, large or small LRs can only be obtained when one probability is small, i.e. when E is highly unlikely conditioned on one of the propositions. This can be seen by the block of darker colour for the smallest value of each of the probabilities. In order to see large or small LRs, we would really have to zoom into the areas of this plot where one probability is tiny, and this cannot be seen using the same scale of this current plot.

## Example: DNA match

Suppose a high quality full DNA profile is recovered from a blood stain at a crime scene. This is known as the **questioned profile**. The profile is analysed and is determined to contain only one person's DNA, making it a **single donor profile**. A suspect is detained and their DNA profile is taken. This is known as the **reference profile**. The reference profile is found to 'match' the questioned profile. Consider the following competing source-level propositions:

- the suspect is the source (of the questioned profile)
- someone other than the suspect is the source (of the questioned profile).

In this situation the DNA 'match' is the observation for which we would like probabilities conditional on the above propositions. The LR is given by

$$\text{LR}=\frac{\text{probability of a match assuming the suspect is the source}}{\text{probability of a match assuming someone other than the suspect is the source}}.$$
To obtain the LR, we need to obtain values for the above conditional probabilities. Let's consider the numerator first. 

The probability of obtaining a match assuming that the suspect is the source is usually set to 1; it is considered to be certain that a match would be obtained if the suspect was the source. This is reasonable although it is not strictly true. There is always the risk of a false positive or other laboratory or technical errors occuring, but it is assumed that the risks of these errors are negligible, especially for high-quality single donor full profiles. 

The denominator, the probability of obtaining a match assuming that someone other than the suspect is the source, is more nuanced. This is known as the **random match probability** (RMP). The RMP reflects how common the recovered profile is in the relevant population for the case. The more common the profile, the higher the RMP and the lower the LR when the formula is applied. The logic behind this is the following: the more common a characteristic is in a population, the worse that characteristic is at discriminating between propositions. Applied in this case, the previous logic states that more common DNA profiles are worse at discriminating between source-level propositions and so they decrease LRs accordingly. Figure \@ref(fig:freq-tree-rmp) visualises an RMP of 1 in 40 million for a population of 40 million and 1 people, which also includes the guilty individual.

```{r freq-tree-rmp, echo=FALSE,fig.cap="Out of 40 million innocent people, 1 DNA profile matches. The RMP is 1 in 40 million. ", out.width = '80%', fig.align = 'center'}
e <- c(1, 2, 1, 3, 2, 4, 2, 5, 3, 6, 3, 7)
v <- c("40,000,001 \npeople", "1\nguilty", "40,000,000\ninnocent", "1\nmatch", "0\nno match", "1\nmatch", "39,999,999\nno match")
freqTree <- graph(edges=e, n=7, directed=FALSE)
V(freqTree)$name <- v

# the commented code below complicates the point
# V(freqTree)$color <- c(rep(colPal[1], 3), 
#                        colPal[4], 
#                        colPal[7],
#                        colPal[7],
#                        colPal[4])
V(freqTree)$color <- c(rep(colPal[1], 7))
V(freqTree)$label.font <- c(1, 1, 2, 1, 1, 2, 1)
par(mar = c(0, 0, 0, 0))
plot(freqTree, vertex.shape="none", vertex.label=V(freqTree)$name,
     vertex.label.color=V(freqTree)$color, vertex.label.font=V(freqTree)$label.font,
     vertex.label.cex=1.2, edge.color="grey70",  edge.width=2,
     layout=layout_as_tree(graph = freqTree, root = 1),
     vertex.size=50)
# legend("bottomright", legend=c("True", "False"),
#        col=colPal[c(4,7)], bty = "n",
#        pch=16)
par(mar = defMar)
```

The RMP is calculated using known frequencies of profiles from specific ethnic groups of people, since ethnic group is a large factor in determining genetic variation. The genetics behind DNA evidence is highly discriminating between individuals, so the RMP is usually very small (it can be in the order of 1 in 1 billion). This results in LRs in the order of millions or billions for competing source level propositions for single donor full profiles. 

In the below interactive example, you can change the value for the RMP and see what affect that has on the LR.

[Interactive example with RMP; display graph of LR as a function of the RMP, the user can highlight points on the graph or input values of the RMP to see what the corresponding LR is.]

In the above discussion, we simplified things by ignoring an important issue of relatedness. For example, the degree of relatedness in a population affects the RMP. This is known as the **population sub-structure** or **co-ancestry**. It is a numerical factor which adjusts the RMP to take account of the co-ancestry present in the relevant population, which again often differs by ethnic background.

We also did not consider direct blood relatives. Our second proposition considered *anyone* other than the suspect. But if we considered close genetic relationships, such as siblings and parents of the suspect, then the RMP would not reflect the probability of matching them. The genetic similarity between these individuals would mean the probability of a match is much higher than the RMP. For this reason, and when there is no reason to suspect close relatives of the suspect, the proposition advocating non-guilt is sometimes changed to

- someone unrelated to the suspect is the source (of the questioned profile),

and the RMP is used to calculate the LR as usual.

There are also other corrective factors that are applied to calculate the conditional probabilities which feed into the LR in the context of DNA evidence, but they are not not mentioned here.

## Updating odds

The LR has a very clear interpretation from Bayes' theorem (Chapter ...)
$$\text{posterior odds} = \text{LR} \times \text{prior odds}.$$
It is the numerical factor by which we multiply odds before particular information (prior odds) in order to obtain odds conditioned on that information (posterior odds); the LR tells us *how much* to update beliefs in light of information. 

We saw in Table \@ref(tab:lr-meaning-table) that values of the LR equal to 1 meant that the event provided equal support for both propositions when compared to each other. Logically, if an event provides equal support for two competing propositions, then it should not update any beliefs we had prior to observing it. If we look at Bayes' theorem above and plug in an LR of 1, then this is exactly what happens. The prior odds between the propositions is equal to the posterior odds between them; observing the event did not change the odds. 

We also saw that when the LR is greater than 1, then the event E provides more support for proposition A than proposition B. The intuition behind that statement is that, after observing E, we should update our prior belief to be more in favour of proposition A (than B) than it was. This is confirmed with Bayes' theorem above; when the LR is greater than 1, then the prior odds in favour of A *increases* to become the posterior odds. Observing the event E was found to be more probable assuming A than B, and so the odds were increased in favour of A by a specific factor, which is given by the LR.

[example in which LR>1 and can be changed with fixed prior odds]

We lastly discuss when the LR is less than 1. In this situation, the event provides more support for proposition B than proposition A. This tells us that we should update our prior belief to be more in favour of proposition B (than A) that it was. Looking at Bayes' theorem, this is exactly what happens; an LR less than 1 means that the prior odds in favour of A are *reduced* to become the posterior odds. Reducing the odds in favour of A means *increasing* the odds in favour of B and so our intuition is confirmed. Observing the event E was found to be more probable assuming B than A, and so the odds were reduced in favour of A (increased in favour of B) by a specific factor, which is given by the LR.

[example with changable LR<1 with fixed prior odds]

## Example: doping (revisited)

Recall the example of detecting doping athletes from Chapter \@ref(exm-doping).

The test returns positive for 95 out of every 100 doping athletes. The test returns negative for 95 out of every 100 non-doping athletes. It was speculated that 2 out of every 100 athletes are doping. We used these numbers to work out the probability of an athlete doping given that they tested positive as around 28%.

A related question is this: How much more likely are we to see a positive test result when the athlete is doping compared to when the athlete is not doping? This question is important as it tells us how informative a positive test result is directly in relation to the information we're interested in: doping versus non-doping. And this is precisely the type of question that an LR can be used to address. 

In order to think about an LR, we need to break this question down into its implied competing propositions and the available evidence. 

Competing propositions:

- the athlete is doping
- the athlete is not doping

Event: 

- a positive test result

The likelihood ratio is given by
$$\text{LR} = \frac{\text{probability of a positive test result assuming the athlete is doping}}{\text{probability of a positive test result assuming the athlete is not doping}}.$$

Note how this is the ratio of the probabilities for the evidence having conditioned upon the competing propositions. The conditional probabilities which contribute to this LR can be extracted from Figure \@ref(fig:freq-tree-lr-doping), in which we assume a population of 10,000 athletes. 
```{r freq-tree-lr-doping, echo=FALSE,fig.cap="The terms which contribute to the LR are shown in bold font. ", out.width = '80%', fig.align = 'center'}
e <- c(1, 2, 1, 3, 2, 4, 2, 5, 3, 6, 3, 7)
v <- c("10,000 \nathletes", "200\ndoping", "9,800\nnot doping", "190\npositive", "10\nnegative", "490\npositive", "9,310\nnegative")
freqTree <- graph(edges=e, n=7, directed=FALSE)
V(freqTree)$name <- v

colPal <- colorblind_pal()(8)
# the commented code below complicates the point
# V(freqTree)$color <- c(rep(colPal[1], 3), 
#                        colPal[4], 
#                        colPal[7],
#                        colPal[7],
#                        colPal[4])
V(freqTree)$color <- c(rep(colPal[1], 7))
V(freqTree)$label.font <- c(1, 2, 2, 2, 1, 2, 1)
par(mar = c(0, 0, 0, 0))
plot(freqTree, vertex.shape="none", vertex.label=V(freqTree)$name,
     vertex.label.color=V(freqTree)$color, vertex.label.font=V(freqTree)$label.font,
     vertex.label.cex=1.2, edge.color="grey70",  edge.width=2,
     layout=layout_as_tree(graph = freqTree, root = 1),
     vertex.size=50)
# legend("bottomright", legend=c("True", "False"),
#        col=colPal[c(4,7)], bty = "n",
#        pch=16)
par(mar = defMar)
```

For the numerator of the LR, "assuming that the athlete is doping"  means that we are only looking at the branches of the tree for the doping athletes. We can see that 190 out of these 200 doping athletes test positive, a probability of 0.95 (this is also the sensitivity in the original example).

For the denominator of the LR, "assuming that the athlete is not doping" means that we only look at the branches of the tree for non-doping athletes. We can see that 490 out of the 9,800 non-doping athletes tested positive, a probability of 0.05 (this is 1 minus the specificity from the original example).

The likelihood ratio is then $\frac{0.95}{0.05}=19$. The meaning of this can be expressed in a number of equivalent ways:

- a positive test updates our prior odds that the athlete is doping, increasing them by a factor of 19,
- a positive test is 19 times more likely to be observed from doping athletes than a positive result from non-doping athletes,
- a positive test result provides 19 times more support for the proposition that the athlete is doping compared to not doping. 

All of these expressions comment on the relative probability of observing a positive test result under the assumptions of the athlete doping and not doping. They do **not** state a value for the probabilities of the athlete doping or not, and they do **not** state that the athlete is 19 times more likley to be doping than not. To believe the latter would be to illegitimately transpose the conditional and commit the prosecutor's fallacy [insert section reference]. 

To finish this example, let's take a look at the odds formulation of the question from Section \@ref(exm-doping): what are the odds of the athlete doping versus not doping given a positive result of the test?

From Figure \@ref(fig:freq-tree-lr-doping) we can extract the odds of a randomly selected athlete doping, versus not, prior to being tested. This is given by $\frac{200}{9800}$, which can be simplified to $\frac{1}{49}$ and also expressed as odds of $1:49$, or 49 to 1 against doping.

Now, using Bayes' theorem and the LR, we find the posterior odds to be
\begin{align}
  \text{posterior odds} &= \text{LR} \times \text{prior odds}, \\
  \text{posterior odds} &= 19 \times \frac{1}{49}, \\
  \text{posterior odds} &= \frac{19}{49},
\end{align}
corresponding to posterior odds of $19:49$, or 49 to 19 against doping given a positive test result. Converting this back to probability gives $\frac{19}{19+49}=0.2794118$, about 28%. This is the same as the answer that we worked out in Section \@ref(exm-doping).

Even though the likelihood ratio for a positive test gave support in favour of the athlete doping, the posterior probability for the proposition that the athlete is doping is still rather small. This is an important point; the likelihood ratio alone does not tell us anything about the absolute value of the posterior probability for a proposition, it only tells us the relative value compared to the prior probability. 

## Quantifying probative value

So far we have considered a generic event E and propositions A and B. When we view this framework from the perspective of a forensic evaluation, the event E can be seen as a piece of evidence and the propositions A and B are the propositions put forward by the prosecution and defence, hereon referred to as $H_p$ and $H_d$. These can be thought of as the prosecution and defence's claimed version of events, the truth of which we are uncertain.

Within this specific situation, the LR tells us the relative support that a piece of evidence provides for $H_p$ or $H_d$. In this sense, the LR conveys the **probative value** of a piece of evidence. It tells us how much more likely a piece of evidence is under the prosecution's version of events when compared to the defence's version of events.

This interpretation of the LR is one of the reasons why it is advocated as a tool to quantify expert testimony. It is the role of the expert witness to present the probative value of scientific evidence within their domain of expertise to the court. The LR provides a logical means to achieve this. The fact finder can then use the probative value of evidence given by the LR to reason about the truth of $H_p$ or $H_d$. This process can clearly be seen using Bayes' theorem again, expanded on below.

Using E as a specific piece of evidence and the specific propositions $H_p$ and $H_d$, the odds form of Bayes' theorem becomes
$$\frac{\text{probability of } H_p \text{ having accounted for the evidence}}{\text{probability of } H_d \text{ having accounted for the evidence}}=\text{LR}\times\frac{\text{prior probability of } H_p}{\text{prior probability of } H_d}.$$
It can be seen that the LR updates beliefs about $H_p$ and $H_d$. Notice how beliefs about $H_p$ and $H_d$ are for the fact finder to determine, and the LR is provided by the expert witness. This is the role that the LR plays with the fact finder: the expert witness provides the LR, and in doing so provides the quantitative factor by which the fact finder should update their odds of each counsel's version of events.

## Combining evidence

LRs can also be used to consider the value of multiple pieces of evidence together. When the individual pieces of evidence are regarded as statistically independent (Chapter ...), we can use the multiplication rule (Chapter ...) to multiply their individual LRs to obtain a combined LR. If the two pieces of evidence are labelled as $E_1$ and $E_2$, then the interpretation of the LR becomes: how much more likely is it that $E_1$ **and** $E_2$ are observed if $H_p$ is true, rather than if $H_d$ is true. Combining evidence like this is the standard approach in DNA evidence evaluation. 

## Example: DNA loci



## Robustness

The LR is open to the same type of scrutiny as most other statistics. Two main reasons for this are:

1. The LR is formed using empirical observations where possible. These may be limited in their sample size and precision, they may contain bias, and they may also vary over time amongst other factors.
2. LRs formed using an expert's opinion are always subjective. Even if an opinion is widely held within a particular community of expertise, it is still subjective (though it may be less subjective than a widely disputed belief).

The degree to which an LR can withstand scrutiny due to the above reasons is termed its robustness. If an LR still seems reasonable and reliable after having assessed it from multiple perspectives (e.g. the sample size of a database which has been informed it, how appropriate that database was for the specific case circumstances, etc.) then it is robust. If an LR does not seem reasonable and reliable after this assessment process, then it is not robust. It is worth noting that an LR which is not robust might still be the best LR in the case circumstances, e.g. if there is a severe lack of data and expertise to inform the LR in the first place. 

An LR is only as robust as the probabilities from which it is formed. Any critical assessment of an LR is only a critical assessment of its underlying probabilities. It is not an assessment of the inherent properties that taking a ratio of two probabilities might give rise to. If an expert gives an LR as an order of magnitude, then the underlying order of magnitude assignments of the probabilities should be coherent with this. For example, if the LR is thought to be between 100-1000, then an order of magnitude assignment of the probability of $E$ assuming $H_d$ cannot be 0.01-0.1 as this would constrain the LR to be between 10-100.

Assessing the robustness of an LR is aided by making a distinction between types of information that the expert uses when constructing conditional probabilities. In the Primer (citation) this information is divided into two categories:

-[S]: knowledge derived from robust systematic studies, ideally published, where the relevant features have been measured and studied statistically.

-[E]: knowledge derived from personal experience, i.e. the expert's training and professional experience in the forensic specialism.

Robustness of an LR informed by knowledge from the [S] category can be assessed by focussing on the quoted studies and data therein. The study design (observational, randomised controlled trial, etc.) and its limitations might be relevant, as well as its applicability to the present case's circumstances. The robustness of studies and databases can be affected by factors such as sample size, precision of measurements, sampling bias, etc.

Robustness of an LR informed by knowledge from the [E] category can be assessed by focussing on the reliability of the expert's personal experience. This could involve the expert detailing their previous experience and its relevance. The reliability of an expert's personal experience may be informed, for example, by previous proficiency or calibration tests in which the expert has participated. The robustness of these tests may also be assessed, such as whether they were conducted blind and without knowledge that an assessment was taking place, how many times they were repeated, etc.

The [E] category is also more likely to be where expert's dispute, since it contains more subjective knowledge than [S] does. Beliefs in this category may be fringe or generally accepted amongst certain subgroups within the field of expertise. Disagreements between experts may be reasonable and can be presented to the court for examination.

The robustness of a particular LR can also be empirically assessed. This involves changing the input values of either the probabilities which determine the LR, or the values which themselves contribute to those probabilities, and inspecting how sensitive the LR is to these changes. This could also involve defining a set of reasonable values which could determine the LR, and then seeing the range of values the LR takes for this reasonable set. 

If the LR is practically unaffected by reasonable changes, or has a small range within the set of reasonable input values, then it is robust. If the LR is highly affected by minor changes, or has a large range within the set of reasonable input values, then it not so robust. 

[interactive example changing probability inputs to the LR]

## Communication

We have looked at the calculation and conceptual meaning of the LR, as well as how to assess its robustness. We now turn our attention to communicating the LR to others. Whereas the previous stages of this chapter may be conducted before evidence is presented to the court, the communication of the LR is present within the courtroom itself and it is not left to the expert witness alone. 

It cannot be stressed how important this communication stage is; even if it is agreed that the LR is the appropriate tool to convey the value of scientific evidence, its effectiveness is nothing without it being understood by those who have to use it to make decisions. This means that the LR needs to be effectively communicated **to** fact-finders and legal counsel, as well as effectively communicated **by** expert witnesses, legal counsel, and the judge if it is contained within their instructions to jurors for a particular case. It is a shared responsibility.

As shown in this chapter, LRs can be communicated using a number of different strategies. We finish the chapter with a short recap of those strategies. [Would be nice to include some of the evidence supporting each of them too.]

Suppose the following scenario:

Evidence:

- $E$: Blood-spatter pattern on the defendant's jeans. The blood has been accepted by both counsels as originating from the complainant. 

Propositions:

- $H_p$: the defendant kicked the complainant
- $H_d$: the defendant did not kick the complainant but was present during the attack. The defendant claims to have been standing some distance from the attack.

An expert witness has stated that the probability of $E$ assuming $H_p$ to be true is 0.1. The expert also stated that the probability of observing $E$ assuming $H_d$ to be true (and based on information such as where the defendant claims to have been standing during the attack) is 0.0001. This gives an LR of $\frac{0.1}{0.0001}=1000$. 

The most raw form of communicating this LR is in its numerical format. Such a statement could read like this:

> This pattern of blood-staining is 1000 times more likely to be seen if the defendant kicked the complainant, rather than if the defendant did not kick the complainant but was present during the attack and was standing in the location as described in their statement.

Converting an LR of 1000 into a verbal statement using Table \@ref(tab:verbal-scale-table) could lead to a statement such as:

> This pattern of blood-staining provides strong support for the defendant having kicked the complainant, rather than the defendant not having kicked the complainant but having been present during the attack and was standing in the location as described in their statement.

Since the conditional probabilities which determine the LR are made explicit in this example (this is not common practice), then the LR can also be communicated visually using natural frequencies in Figure \@ref(fig:freq-tree-lr-kicking):

```{r freq-tree-lr-kicking, echo=FALSE,fig.cap="The terms which contribute to the LR are shown in bold font. Since the populations we assumed are the same size, the LR is just 1000 divided by 1, or just 1000.", out.width = '80%', fig.align = 'center'}
e <- c(1, 2, 1, 3)
v <- c("10,000\nkickers", "10,000\nnon-kickers", "1000\nthis\npattern", "9000\nnot this\npattern", "1\nthis\npattern", "9999\nnot this\npattern")
freqTreeKick <- graph(edges=e, n=3, directed=FALSE)
freqTreeNonKick <- graph(edges=e, n=3, directed=FALSE)
V(freqTreeKick)$name <- v[c(1, 3, 4)]
V(freqTreeNonKick)$name <- v[c(2, 5, 6)]

colPal <- colorblind_pal()(8)
# the commented code below complicates the point
# V(freqTree)$color <- c(rep(colPal[1], 3), 
#                        colPal[4], 
#                        colPal[7],
#                        colPal[7],
#                        colPal[4])
treeCol <- c(rep(colPal[1], 3))
V(freqTreeKick)$color <- treeCol
V(freqTreeNonKick)$color <- treeCol
treeFont <- c(2, 2, 1)
V(freqTreeKick)$label.font <- treeFont
V(freqTreeNonKick)$label.font <- treeFont
par(mar = c(0, 0, 0, 0), mfrow=c(1, 2))
plot(freqTreeKick, vertex.shape="none", vertex.label=V(freqTreeKick)$name,
     vertex.label.color=V(freqTreeKick)$color, vertex.label.font=V(freqTreeKick)$label.font,
     vertex.label.cex=1.2, edge.color="grey70",  edge.width=2,
     layout=layout_as_tree(graph = freqTreeKick, root = 1),
     vertex.size=50)
# legend("bottomright", legend=c("True", "False"),
#        col=colPal[c(4,7)], bty = "n",
#        pch=16)
plot(freqTreeNonKick, vertex.shape="none", vertex.label=V(freqTreeNonKick)$name,
     vertex.label.color=V(freqTreeNonKick)$color, vertex.label.font=V(freqTreeNonKick)$label.font,
     vertex.label.cex=1.2, edge.color="grey70",  edge.width=2,
     layout=layout_as_tree(graph = freqTreeNonKick, root = 1),
     vertex.size=50)
par(mar = defMar, mfrow=c(1, 1))
```

```{r lr-pie-kick, echo=FALSE, fig.cap="Relative size of E given H_p versus E given H_d", out.width = '80%', fig.align = 'center'}
df <- data.frame(prob=c("E given H_p", "E given H_d"), num=c(1000,1))
bp<- ggplot(df, aes(x="", y=num, fill=prob))+
geom_bar(width = 1, stat = "identity")
pie <- bp + coord_polar("y", start=0) + scale_fill_manual(values=c(colPal[6], colPal[7])) + theme_minimal()
pie
```

An accompanying verbal statement could be:

> Out of 10,000 kickers in an equivalent situation to the defendant in the prosecution's version of events, this blood pattern would be found on 1000 of them. Out of 10,000 non-kickers in an equivalent situation to the defendant in the defence's version of events, this blood pattern would be found on 1 of them. 

Notice how the expert did not specify a prior probability of being the kicker or not, and so we had to split the trees into two groups, one for the kickers, and one for the non-kickers.

In expert reports, the currently endorsed approach by the Forensic Science Regulator is to communicate LRs using their numerical value possibly converted into the verbal statements given in Table \@ref(tab:verbal-scale-table). The effectiveness of this method of communicating the LR (as well as others) is an active area of scientific research, and has the potential to change as we gather a better understanding of how those communications are received and used by those within the courtroom.

## More information

## Exercises