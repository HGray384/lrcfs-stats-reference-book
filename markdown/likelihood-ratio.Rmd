# Likelihood ratio as value of evidence {#likelihood-ratio}

```{r package-load-likelihood-ratio, include=FALSE}
source("./code/helper-functions.R")
# check and load the libraries
needPackages("igraph",
              "ggthemes",
              "kableExtra",
              "tidyverse")
# set some useful variables
source("./code/useful-variables.R")
```

This Chapter introduces the likelihood ratio

## Definition and properties

We're in a situation in which we have two competing propositions, A and B. We observe an event E, and wish to know whether E supports A or B more. The likelihood ratio (LR) quantifies this support.

The LR consists of the probability of observing E conditioned on A being true, divided by the probability of observing E conditioned on B being true. As a formula it is written as
$$\text{LR}=\frac{\text{probability of E assuming A is true}}{\text{probability of E assuming B is true}}.$$

The trick here is that by assuming each proposition to be true in turn, we can see how much more likely the event was to occur in A's version of events compared to B's.

Since each term in the LR is a probability, their value must lie between 0 and 1. This means that the LR itself must be between 0 and $\infty$. Values of the LR which are greater than 1 indicate relative support for A compared to B, since it means that the probability of E assuming that A is true is greater than the probability of E assuming B is true. Values of the LR which are less than 1 indicate relative support for b compared to A, since it means that the probability of E assuming that B is true is greater than the probability of E assuming A is true. This is shown in Figure

```{r lr-bound, echo=FALSE, fig.cap="The LR is bounded between 0 and positive infinity. Very large values of the LR occur where the probability of E assuming B is true is very small.  ", out.width = '80%', fig.align = 'center'}
gridVals <- 20
prob1 <- prob2 <- seq(0, 1, length.out = gridVals)[-1]
vars <- expand.grid(prob1, prob2)
lrDf <- tibble(prob1 = vars$Var1, prob2 = vars$Var2)%>%
  mutate(lr = prob1/prob2)

ggplot(lrDf, aes(x=prob2, y=prob1, fill=lr)) +
  geom_tile() +
  xlab("probability of E assuming B is true") +
  ylab("probability of E assuming A is true") +
  scale_x_continuous(expand = c(0, 0)) +
  scale_y_continuous(expand = c(0, 0)) +
  scale_fill_gradientn(colors = c(colPal[7],
                                  "white",
                                  colPal[6]),
                       name="LR",
                       values = c(0, 1/max(lrDf$lr), 1))
```

## Example: DNA match

Suppose a high quality full DNA profile is recovered from a blood stain at a crime scene. This is known as the **questioned profile**. The profile is analysed and is determined to contain only one person's DNA, making it a **single donor profile**. A suspect is detained and their DNA profile is taken. This is known as the **reference profile**. The reference profile is found to 'match' the questioned profile. Consider the following competing source-level propositions:

- the suspect is the source (of the questioned profile)
- someone other than the suspect is the source (of the questioned profile).

In this situation the DNA 'match' is the observation for which we would like a probability. The LR is given by

$$\text{LR}=\frac{\text{probability of a match assuming the suspect is the source}}{\text{probability of a match assuming someone other than the suspect is the source}}.$$
To obtain the LR, we need to obtain values for the above conditional probabilities. Let's consider the numerator first. 

The probability of obtaining a match assuming that the suspect is the source is usually set to 1; it is considered to be certain that a match would be obtained if the suspect was the source. This is reasonable although it is not strictly true. There is always the risk of a false positive or other laboratory or technical errors occuring, but it is assumed that the risks of these errors are negligible, especially for high-quality full profiles. 

The denominator, the probability of obtaining a match assuming that someone other than the suspect is the source, is more nuanced. This is known as the **random match probability** (RMP). The RMP reflects how common the recovered profile is in the relevant population for the case. The more common the profile, the higher the RMP and the lower the LR when the above formula is applied. The logic behind this is the following: the more common a characteristic is in a population, the worse that characteristic is at discriminating between propositions. Figure \@ref(fig:freq-tree-rmp) visualises an RMP of 1 in 40 million for a population of 40 million and 1 people, which also includes the guilty individual.

```{r freq-tree-rmp, echo=FALSE,fig.cap="Out of 40 million innocent people, 1 DNA profile matches. The RMP is 1 in 40 million. ", out.width = '80%', fig.align = 'center'}
e <- c(1, 2, 1, 3, 2, 4, 2, 5, 3, 6, 3, 7)
v <- c("40,000,001 \npeople", "1\nguilty", "40,000,000\ninnocent", "1\nmatch", "0\nno match", "1\nmatch", "39,999,999\nno match")
freqTree <- graph(edges=e, n=7, directed=FALSE)
V(freqTree)$name <- v

# the commented code below complicates the point
# V(freqTree)$color <- c(rep(colPal[1], 3), 
#                        colPal[4], 
#                        colPal[7],
#                        colPal[7],
#                        colPal[4])
V(freqTree)$color <- c(rep(colPal[1], 7))
V(freqTree)$label.font <- c(1, 1, 2, 1, 1, 2, 1)
par(mar = c(0, 0, 0, 0))
plot(freqTree, vertex.shape="none", vertex.label=V(freqTree)$name,
     vertex.label.color=V(freqTree)$color, vertex.label.font=V(freqTree)$label.font,
     vertex.label.cex=1.2, edge.color="grey70",  edge.width=2,
     layout=layout_as_tree(graph = freqTree, root = 1),
     vertex.size=50)
# legend("bottomright", legend=c("True", "False"),
#        col=colPal[c(4,7)], bty = "n",
#        pch=16)
par(mar = defMar)
```

The RMP is calculated using known frequencies of profiles from specific ethnic groups of people, since ethnic group is a large factor in determining genetic variation. The genetics behind DNA evidence is highly discriminating between individuals, so the RMP is usually very small (it can be in the order of 1 in 1 billion). This results in LRs in the order of millions or billions for competing source level propositions for single donor full profiles. 

In the below interactive example, you can change the value for the RMP and see what affect that has on the LR.

[Interactive example with RMP; display graph of LR as a function of the RMP, the user can highlight points on the graph or input values of the RMP to see what the corresponding LR is.]

In the above discussion, we made things simplified by ignoring an important issue of relatedness. For example, the degree of relatedness in a population affects the RMP. Our second proposition considered anyone other than the suspect. But if we considered close genetic relationships, such as siblings and parents of the suspect, then the RMP would not reflect the probability of a match. The genetic similarity between these individuals would mean the probability of a match is much higher than the RMP. For this reason, and when there is no reason to suspect close relatives of the suspect, the proposition advocating non-guilt is sometimes changed to

- someone unrelated to the suspect is the source,

and the RMP is used as usual. 

## Updating odds

The LR has a very clear interpretation from Bayes' theorem
$$\text{posterior odds} = \text{LR} \times \text{prior odds}.$$
It is the numerical factor by which we multiply odds before particular information (prior odds) in order to obtain odds conditioned on that information (posterior odds). It tells us how to update beliefs in light of information. 

## Example: doping (revisited)

Recall the example of detecting doping athletes from Chapter \@ref(false-positives).

The test returns positive for 95 out of every 100 doping athletes. The test returns negative for 95 out of every 100 non-doping athletes. It was speculated that 2 out of every 100 athletes are doping. We used these numbers to work out the probability of an athlete doping given that they tested positive as around 28%.

A related question is this: How much more likely are we to see a positive test result when the athlete is doping compared to when the athlete is not doping? This question is important as it tells us how informative a positive test result is directly in relation to the information we're interested in: doping versus non-doping. And this is precisely the type of question that an LR addresses. 

In order to think about an LR, we need to break this question down into its implied competing propositions and the available evidence. 

Competing propositions:

- the athlete is doping
- the athlete is not doping

Evidence: 

- a positive test result

The likelihood ratio is given by
$$\text{LR} = \frac{\text{probability of a positive test result assuming the athlete is doping}}{\text{probability of a positive test result assuming the athlete is not doping}}.$$

Note how this is the ratio of the probabilities for the evidence having conditioned upon the competing propositions. The conditional probabilities which contribute to this LR can be extracted from Figure \@ref(fig:freq-tree-lr-doping), in which we assume a population of 10,000 athletes. 
```{r freq-tree-lr-doping, echo=FALSE,fig.cap="The terms which contribute to the LR are shown in bold font. ", out.width = '80%', fig.align = 'center'}
e <- c(1, 2, 1, 3, 2, 4, 2, 5, 3, 6, 3, 7)
v <- c("10,000 \nathletes", "200\ndoping", "9,800\nnot doping", "190\npositive", "10\nnegative", "490\npositive", "9,310\nnegative")
freqTree <- graph(edges=e, n=7, directed=FALSE)
V(freqTree)$name <- v

colPal <- colorblind_pal()(8)
# the commented code below complicates the point
# V(freqTree)$color <- c(rep(colPal[1], 3), 
#                        colPal[4], 
#                        colPal[7],
#                        colPal[7],
#                        colPal[4])
V(freqTree)$color <- c(rep(colPal[1], 7))
V(freqTree)$label.font <- c(1, 2, 2, 2, 1, 2, 1)
par(mar = c(0, 0, 0, 0))
plot(freqTree, vertex.shape="none", vertex.label=V(freqTree)$name,
     vertex.label.color=V(freqTree)$color, vertex.label.font=V(freqTree)$label.font,
     vertex.label.cex=1.2, edge.color="grey70",  edge.width=2,
     layout=layout_as_tree(graph = freqTree, root = 1),
     vertex.size=50)
# legend("bottomright", legend=c("True", "False"),
#        col=colPal[c(4,7)], bty = "n",
#        pch=16)
par(mar = defMar)
```

For the numerator of the LR, "assuming that the athlete is doping"  means that we are only looking at the branches of the tree for the doping athletes. We can see that 190 out of these 200 doping athletes test positive, a probability of 0.95 (this is also the sensitivity in the original example).

For the denominator of the LR, "assuming that the athlete is not doping" means that we only look at the branches of the tree for non-doping athletes. We can see that 490 out of the 9,800 non-doping athletes tested positive, a probability of 0.05 (this is 1 minus the specificity from the original example).

The likelihood ratio is then $\frac{0.95}{0.05}=19$. The meaning of this can be expressed in a number of equivalent ways:

- a positive test updates our prior odds that the athlete is doping, increasing them by a factor of 19,
- a positive test is 19 times more likely to be observed from doping athletes than a positive result from non-doping athletes,
- a positive test result provides 19 times more support for the proposition that the athlete is doping compared to not doping. 

All of these expressions comment on the relative probability of observing a positive test result under the assumptions of the athlete doping and not doping. They do **not** state a value for the probabilities of the athlete doping or not, and they do **not** state that the athlete is 19 times more likley to be doping than not. To believe the latter would be to illegitimately transpose the conditional and commit the prosecutor's fallacy [insert section reference]. 

To finish this example, let's take a look at the odds formulation of the question from Section \@ref(exm-doping): what are the odds of the athlete doping versus not doping given a positive result of the test?

From Figure \@ref(fig:freq-tree-lr-doping) we can extract the odds of a randomly selected athlete doping, versus not, prior to being tested. This is given by $\frac{200}{9800}$, which can be simplified to $\frac{1}{49}$ and expressed as odds of $1:48$, or 48 to 1 against doping.

Now, using Bayes' theorem and the LR, we find the posterior odds to be
\begin{align}
  \text{posterior odds} &= \text{LR} \times \text{prior odds} \\
  \frac{19}{49} &= 19 \times \frac{1}{49},
\end{align}
corresponding to posterior odds of $19:48$, or 48 to 19 against doping given a positive test result. Converting this back to probability gives $\frac{19}{19+48}=0.2835821$, about 28%. This is the same as the answer that we worked out in Section \@ref(exm-doping).

Even though the likelihood ratio for a positive test gave support in favour of the athlete doping, the posterior probability for the proposition that the athlete is doping is still rather small. This is an important point; the likelihood ratio alone does not tell us anything about the absolute value of the posterior probability for a proposition, it only tells us the relative value compared to the prior probability. 

This illustrates the difference between a probability for a proposition versus a probability for the evidence conditioned upon a proposition. 

## Probative value of evidence



The interpretation of the LR as an update of the prior odds when conditioned on specific information

## Combining evidence


## Example: DNA loci


## Robustness

- [S] versus [E] in the primer
- changes in assumptions/values


[interactive example changing probability inputs to the LR]

## Communication

[verbal scale]

## Interpretation

## More information

## Exercises