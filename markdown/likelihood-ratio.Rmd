# Likelihood ratio to evaluate uncertainty {#likelihood-ratio}

```{r package-load-likelihood-ratio, include=FALSE}
source("./code/helper-functions.R")
# check and load the libraries
needPackages("igraph",
              "ggthemes",
              "kableExtra",
              "tidyverse",
              "plotly")
# set some useful variables
source("./code/useful-variables.R")
```

Using the theory of probability and propositions, we have seen how uncertainty can be described and framed around the key facts of a criminal case. The final idea is to evaluate the uncertainty surrounding evidence in a way which satisfies probability theory, so that it remains logically consistent, and also so that it assists the court in determining the truth of key propositions. This is achieved using the likelihood ratio, which has been mentioned in previous chapters. 

In this chapter, we focus on the likelihood ratio in detail. We revisit how it relates to probabilities, propositions, and evidence, how it used to quantify probative value, what factors can affect its robustness, and how it is categorised and communicated to the court.

## Relative support for competing propositions

Suppose that there are two competing propositions, $H_p$ for the prosecution and $H_d$ for the defence. There is observed evidence E, and the expert needs to determine whether E was more likely assuming $H_p$ or $H_d$, since this will assist the court in assessing the truth of $H_p$ or $H_d$. If E is more likely assuming $H_p$ were true compared to if $H_d$ were true, then the evidence E provides more support for $H_p$ than $H_d$, and vice versa if E is more likely assuming $H_d$ to be true compared to $H_p$. The likelihood ratio (LR) quantifies the magnitude of this support.

The LR is the relative size of the probability of observing E conditioned on $H_p$, compared to the probability of observing E conditioned on $H_d$. Mathematically, this is equivalent to dividing the probability of observing E conditioned on $H_p$, by the probability of observing E conditioned on $H_d$. As a formula it is written as
$$\text{LR}=\frac{\text{probability of E assuming }H_p \text{ is true}}{\text{probability of E assuming }H_d \text{ is true}}.$$

By assuming each of the competing propositions to be true, we can see how much more likely E was to occur in the prosecution's version of events compared to the defence's.

Since each term in the LR is a probability, their value must lie between 0 and 1. This means that the LR itself must be between 0 and $\infty$. Values of the LR which are greater than 1 indicate relative support in favour of $H_p$ compared to $H_d$, since it means that the probability of E assuming that $H_p$ is true is greater than the probability of E assuming $H_d$ is true. Values of the LR which are less than 1 indicate relative support in favour of $H_d$ compared to $H_p$, since it means that the probability of E assuming that $H_d$ is true is greater than the probability of E assuming $H_p$ is true. Values of the LR which are equal to 1 indicate that E provides equal support for $H_p$ and $H_d$ when compared to each other. This is shown in Table \@ref(tab:lr-meaning-table).

```{r lr-meaning-df, include=FALSE}
lrDf <- tibble("LR" = c("less than 1",
                        "equal to 1",
                        "greater than 1"),
                  "Meaning"=c("More support for B compared to A",
                              "Equal support for both when compared to each other",
                              "More support for A compared to B"))
```

```{r lr-meaning-table, echo=FALSE}
options(kableExtra.html.bsTable = T)
lrDf %>%
  knitr::kable(booktabs = TRUE, escape = F, align = "c",
             caption = 'Meaning of values of the LR for event E.') %>%
  kable_styling(c("striped", "condensed"), 
                latex_options = "striped")
```

## Strength of support

The magnitude of the LR conveys the strength of the support which E provides for $H_p$ or $H_d$ in comparison to each other. LRs of 1,000,000 and 10 both provide support in favour of proposition $H_p$ compared to $H_d$, but the LR of 1,000,000 provides much stronger support than the LR of 10 does. Similarly, LRs of 0.0000001 and 0.1 provide support in favour of proposition $H_d$ compared to $H_p$, but the LR of 0.0000001 provides much stronger support than the LR of 0.1 does. As the value of the LR gets further away from 1, the stronger the support is in favour of proposition $H_p$ or $H_d$ (depending on whether the LR is greater or less than 1) when compared to its competitor.

One method to convey the numerical strength of an LR is to place it into a category of verbal expressions based on its numerical magnitude. Multiple suggested categorisations exist, such as the example given below in Table \@ref(tab:verbal-scale-table).

```{r verbal-scale-df, include=FALSE}
strength <- c("weak",
              "moderate",
              "moderately strong",
              "strong",
              "very strong",
              "extremely strong")
strengthSup <- paste(strength, "support")
props <- c("for A compared to B",
           "for B compared to A")
verbExpr <- c(paste(rev(strengthSup), props[2]),
              "equal support for A and B",
              paste(strengthSup, props[1]))
lrRange <- c("less than 0.000001",
             "at least 0.000001 but less than 0.0001",
             "at least 0.0001 but less than 0.001",
             "at least 0.001 but less than 0.01",
             "at least 0.01 but less than 0.1",
             "at least 0.1 but less than 1",
             "1",
             "at least 1 but less than 10",
             "at least 10 but less than 100",
             "at least 100 but less than 1000",
             "at least 1000 but less than 10,000",
             "at least 10,000 but less than 1,000,000",
             "at least 1,000,000")
vsDf <- dplyr::tibble("LR"=lrRange, "verbal expression"=verbExpr)
```


```{r verbal-scale-table, echo=FALSE}
options(kableExtra.html.bsTable = T)
vsDf %>%
  knitr::kable(booktabs = TRUE, escape = F, align = "c",
             caption = 'Verbal expressions to convey the strength of numerical LRs.') %>%
  kable_styling(c("striped", "condensed"), 
                latex_options = "striped")


```

The LR is determined by the values of its underlying conditional probabilities. Figure \@ref(fig:lr-function) shows how the value of the LR changes based on the values of these probabilities. Hover your mouse over the graph to see the values of the conditional probabilities and the resulting LR. 

```{r lr-function, echo=FALSE, fig.cap="LR values as its underlying probabilities vary. Values are coloured by their support for either proposition: blue is support in favour of $H_p$ compared to $H_d$, and orange is support for $H_d$ compared to $H_p$. White means equal support for both.", out.width = '100%', fig.align = 'center'}
gridVals <- 101
prob1 <- prob2 <- seq(0, 1, length.out = gridVals)[-1]
vars <- expand.grid(prob1, prob2)
lrDf <- tibble(prob1 = vars$Var1, prob2 = vars$Var2)%>%
  mutate(lr = prob1/prob2)

graph = ggplot(lrDf, aes(x=prob2, y=prob1, fill=lr)) +
  geom_tile(aes(text = paste('probability of E assuming Hp is true: ', prob1,
                             '<br>probability of E assuming Hd is true:', prob2,
                             '<br>LR: ',lr))) +
  xlab("probability of E assuming Hd is true") +
  ylab("probability of E assuming Hp is true") +
  scale_x_continuous(expand = c(0, 0)) +
  scale_y_continuous(expand = c(0, 0)) +
  scale_fill_gradientn(colors = c(colPal[7],
                                  colPal[2],
                                  "white",
                                  colPal[3],
                                  colPal[6]),
                       breaks = c(0.01, 0.1,
                                  1,10, 100),
                       labels=c(0.01, 0.1,
                                  1,10, 100),
                       name="LR", trans = "log"
                       # values = c(0, 0.4, 
                       #            0.5, 
                       #            0.6, 1)
  )

ggplotly(graph, tooltip = "text")
  
```

## Example: DNA match

Suppose that a high quality full DNA profile is recovered from a blood stain at a crime scene. This is known as the **questioned profile**. The profile is analysed and is determined to contain only one person's DNA, making it a **single donor profile**. A suspect is detained and their DNA profile is taken. This is known as the **reference profile**. The reference profile is found to 'match' the questioned profile. Consider the following competing source-level propositions:

- $H_p$: the suspect is the source (of the questioned profile),
- $H_d$: someone other than the suspect is the source (of the questioned profile).

In this situation the DNA 'match' is the evidence for which we would like probabilities conditioned on the above propositions. The LR is given by

$$\text{LR}=\frac{\text{probability of a match assuming the suspect is the source}}{\text{probability of a match assuming someone other than the suspect is the source}}.$$
To obtain the LR, we need to obtain values for the above conditional probabilities. Consider the numerator first. 

The probability of obtaining a match assuming that the suspect is the source is usually set to 1; it is considered to be certain that a match would be obtained if the suspect were truly the source. This is reasonable although it is not strictly true. There is always the risk of a false positive or other laboratory or technical errors occurring, but in practice it is typically assumed that the risks of these errors are negligible, especially for high-quality single donor full profiles. If the questioned profile is not high quality, or another factor affecting the integrity of the match is present for a given case, then the expert might assign a probability of less than 1 to this expression.

The probability of obtaining a match assuming that someone other than the suspect is the source is more complex to assign a value to. This is known as the **random match probability** (RMP). The RMP reflects how common the recovered profile is in the relevant population for the case. The more common the profile, the higher the RMP and the lower the LR when the formula is applied; The LR is inversely related to the RMP. The logic behind this is the following: the more common a characteristic is in a population, the worse that characteristic is at discriminating between source level propositions. More common DNA profiles are worse at discriminating between source-level propositions and so they result in smaller LRs when compared to uncommon profiles. Figure \@ref(fig:freq-tree-rmp) displays the expected frequency tree for a RMP of 1 in 40 million in a population of 40 million and 1 people (which includes the guilty individual).

```{r freq-tree-rmp, echo=FALSE,fig.cap="Out of 40 million innocent people, 1 DNA profile matches. The RMP is 1 in 40 million. ", out.width = '80%', fig.align = 'center'}
e <- c(1, 2, 1, 3, 2, 4, 2, 5, 3, 6, 3, 7)
v <- c("40,000,001 \npeople", "1\nguilty", "40,000,000\ninnocent", "1\nmatch", "0\nno match", "1\nmatch", "39,999,999\nno match")
freqTree <- graph(edges=e, n=7, directed=FALSE)
V(freqTree)$name <- v

# the commented code below complicates the point
# V(freqTree)$color <- c(rep(colPal[1], 3), 
#                        colPal[4], 
#                        colPal[7],
#                        colPal[7],
#                        colPal[4])
V(freqTree)$color <- c(rep(colPal[1], 7))
V(freqTree)$label.font <- c(1, 1, 2, 1, 1, 2, 1)
par(mar = c(0, 0, 0, 0))
plot(freqTree, vertex.shape="none", vertex.label=V(freqTree)$name,
     vertex.label.color=V(freqTree)$color, vertex.label.font=V(freqTree)$label.font,
     vertex.label.cex=1.2, edge.color="grey70",  edge.width=2,
     layout=layout_as_tree(graph = freqTree, root = 1),
     vertex.size=50)
# legend("bottomright", legend=c("True", "False"),
#        col=colPal[c(4,7)], bty = "n",
#        pch=16)
par(mar = defMar)
```

The figure highlights that this RMP reflects the belief that out of 40 million innocent individuals from a relevant population, it is expected that 1 will match the questioned profile. 

In this example, the LR is 40 million. This means that the DNA match is 40 million times more likely if the suspect were the source of the bloodstain compared to if they were not. From the verbal scale in Table \@ref(tab:verbal-scale-table), this LR translates into extremely strong support for $H_p$ compared to $H_d$. Note that this LR is for competing source level propositions. If the propositions were moved to the activity level, then the LR could be considerably reduced depending on the case circumstances. It is important to keep in mind the specific competing propositions to which any given LR refers.

The RMP is calculated using frequency databases of profiles from specific ethnic groups of people, since ethnic group is a large factor in determining genetic variation. The genetics behind DNA evidence is highly discriminating between individuals, so the RMP is usually very small. This results in LRs which can be very large for competing source level propositions for single donor full profiles. 

In the below interactive example, you can change the value for the RMP and see what affect that has on the LR.

[Interactive example with RMP; display graph of LR as a function of the RMP, the user can highlight points on the graph or input values of the RMP to see what the corresponding LR is.]

The RMP is also affected by other factors, such as the degree of relatedness in a population. This is known as the **population sub-structure** or **co-ancestry**. It is a numerical factor which adjusts the RMP to take account of the co-ancestry present in the relevant population, which can also differ depending on ethnic background.

We did not consider direct blood relatives in our propositions. $H_d$ considered *anyone* other than the suspect. But if there was reason to suspect close relatives of the suspect, such as their siblings or parents, then the RMP as calculated from population frequency databases alone would not reflect the required probability. The genetic similarity between these individuals would mean the probability of a match is higher than the RMP. For this reason, and when there is no reason to suspect close relatives of the suspect, the defence proposition is sometimes constructed as

- $H_d$: someone unrelated to the suspect is the source (of the questioned profile).

There are other corrective factors that are applied to calculate the conditional probabilities which feed into the LR in the context of DNA evidence, but they are not not mentioned here. To learn more about DNA evidence and resulting LR calculations, please see @dnaprimer2017 and @puch2012. 

## Updating odds

The LR has a very clear interpretation from Bayes' rule, which was introduced in Chapter \@ref(probability). The rule states that
$$\text{posterior odds} = \text{LR} \times \text{prior odds}.$$
The LR is the numerical factor by which we multiply prior odds in order to obtain posterior odds. The LR tells us *how much* to update odds in light of new information. 

We saw in Table \@ref(tab:lr-meaning-table) that values of the LR equal to 1 meant that the evidence provided equal support for both propositions when compared to each other. Logically, if evidence provides equal support for two competing propositions, then it should not update any odds prior to having observed it. If we look at Bayes' theorem above and plug in an LR of 1, then this is exactly what happens. The prior odds between the propositions is equal to the posterior odds between them; observing the event did not change the odds. 

We also saw that when the LR is greater than 1, then the evidence provides more support for $H_p$ than proposition $H_d$. The intuition is that the evidence should increase the odds to be more in favour of $H_p$ (compared to $H_d$) than it previously was. This is confirmed with Bayes' rule above; when the LR is greater than 1, then the prior odds in favour of $H_p$ *increases* when becoming the posterior odds. Observing the evidence was found to be more probable assuming $H_p$ than $H_d$, and so the odds were increased in favour of $H_p$ by a factor equal to the LR.

When the LR is less than 1, the evidence provides more support for $H_d$ than $H_p$. This tells us that we should update our prior odds to be more in favour of proposition $H_d$ (compared to $H_p$) that it previously was. According to Bayes' rule, this is exactly what happens; an LR less than 1 means that the prior odds in favour of $H_p$ are *reduced* when becoming the posterior odds. Reducing the odds in favour of $H_p$ means *increasing* the odds in favour of $H_d$. Observing the evidence was found to be more probable assuming $H_d$ than $H_d$, and so the odds were reduced in favour of $H_p$ (increased in favour of $H_d$) by a factor equal to the LR.

## Example: doping (revisited)

Recall the example of detecting doping athletes from Chapter \@ref(exm-doping).

The test returns positive for 95 out of every 100 doping athletes. The test returns negative for 95 out of every 100 non-doping athletes. It was speculated that 2 out of every 100 athletes are doping. We used these numbers to work out the probability of an athlete doping given that they tested positive as around 28%.

A related question is this: How much more likely are we to see a positive test result when the athlete is doping compared to when the athlete is not doping? This question is important as it tells us how informative a positive test result is directly in relation to the information we're interested in: doping versus non-doping. And this is precisely the type of question that an LR can be used to address. 

In order to think about an LR, we need to break this question down into its implied competing propositions and the available evidence. 

Competing propositions:

- the athlete is doping
- the athlete is not doping

Event: 

- a positive test result

The likelihood ratio is given by
$$\text{LR} = \frac{\text{probability of a positive test result assuming the athlete is doping}}{\text{probability of a positive test result assuming the athlete is not doping}}.$$

Note how this is the ratio of the probabilities for the evidence having conditioned upon the competing propositions. The conditional probabilities which contribute to this LR can be extracted from Figure \@ref(fig:freq-tree-lr-doping), in which we assume a population of 10,000 athletes. 
```{r freq-tree-lr-doping, echo=FALSE,fig.cap="The terms which contribute to the LR are shown in bold font. ", out.width = '80%', fig.align = 'center'}
e <- c(1, 2, 1, 3, 2, 4, 2, 5, 3, 6, 3, 7)
v <- c("10,000 \nathletes", "200\ndoping", "9,800\nnot doping", "190\npositive", "10\nnegative", "490\npositive", "9,310\nnegative")
freqTree <- graph(edges=e, n=7, directed=FALSE)
V(freqTree)$name <- v

colPal <- colorblind_pal()(8)
# the commented code below complicates the point
# V(freqTree)$color <- c(rep(colPal[1], 3), 
#                        colPal[4], 
#                        colPal[7],
#                        colPal[7],
#                        colPal[4])
V(freqTree)$color <- c(rep(colPal[1], 7))
V(freqTree)$label.font <- c(1, 2, 2, 2, 1, 2, 1)
par(mar = c(0, 0, 0, 0))
plot(freqTree, vertex.shape="none", vertex.label=V(freqTree)$name,
     vertex.label.color=V(freqTree)$color, vertex.label.font=V(freqTree)$label.font,
     vertex.label.cex=1.2, edge.color="grey70",  edge.width=2,
     layout=layout_as_tree(graph = freqTree, root = 1),
     vertex.size=50)
# legend("bottomright", legend=c("True", "False"),
#        col=colPal[c(4,7)], bty = "n",
#        pch=16)
par(mar = defMar)
```

```{block eval=FALSE, include=isDynamicOutput()}
### Interavtive Example

Below is an interactive example showing doping stuff.

```
```{r echo=FALSE}
if(isDynamicOutput()){
  knitr::include_app(getInteractiveLink("tabDopingTest_likelihoodRatio","DopingTest",TRUE), height = '1650px')
}
```

For the numerator of the LR, "assuming that the athlete is doping"  means that we are only looking at the branches of the tree for the doping athletes. We can see that 190 out of these 200 doping athletes test positive, a probability of 0.95 (this is also the sensitivity in the original example).

For the denominator of the LR, "assuming that the athlete is not doping" means that we only look at the branches of the tree for non-doping athletes. We can see that 490 out of the 9,800 non-doping athletes tested positive, a probability of 0.05 (this is 1 minus the specificity from the original example).

The likelihood ratio is then $\frac{0.95}{0.05}=19$. The meaning of this can be expressed in a number of equivalent ways:

- a positive test updates our prior odds that the athlete is doping, increasing them by a factor of 19,
- a positive test is 19 times more likely to be observed from doping athletes than a positive result from non-doping athletes,
- a positive test result provides 19 times more support for the proposition that the athlete is doping compared to not doping. 

All of these expressions comment on the relative probability of observing a positive test result under the assumptions of the athlete doping and not doping. They do **not** state a value for the probabilities of the athlete doping or not, and they do **not** state that the athlete is 19 times more likley to be doping than not. To believe the latter would be to illegitimately transpose the conditional and commit the prosecutor's fallacy [insert section reference]. 

To finish this example, let's take a look at the odds formulation of the question from Section \@ref(exm-doping): what are the odds of the athlete doping versus not doping given a positive result of the test?

From Figure \@ref(fig:freq-tree-lr-doping) we can extract the odds of a randomly selected athlete doping, versus not, prior to being tested. This is given by $\frac{200}{9800}$, which can be simplified to $\frac{1}{49}$ and also expressed as odds of $1:49$, or 49 to 1 against doping.

Now, using Bayes' theorem and the LR, we find the posterior odds to be
\begin{align}
  \text{posterior odds} &= \text{LR} \times \text{prior odds}, \\
  \text{posterior odds} &= 19 \times \frac{1}{49}, \\
  \text{posterior odds} &= \frac{19}{49},
\end{align}
corresponding to posterior odds of $19:49$, or 49 to 19 against doping given a positive test result. Converting this back to probability gives $\frac{19}{19+49}=0.2794118$, about 28%. This is the same as the answer that we worked out in Section \@ref(exm-doping).

Even though the likelihood ratio for a positive test gave support in favour of the athlete doping, the posterior probability for the proposition that the athlete is doping is still rather small. This is an important point; the likelihood ratio alone does not tell us anything about the absolute value of the posterior probability for a proposition, it only tells us the relative value compared to the prior probability. 

## Quantifying probative value

So far we have considered a generic event E and propositions A and B. When we view this framework from the perspective of a forensic evaluation, the event E can be seen as a piece of evidence and the propositions A and B are the propositions put forward by the prosecution and defence, hereon referred to as $H_p$ and $H_d$. These can be thought of as the prosecution and defence's claimed version of events, the truth of which we are uncertain.

Within this specific situation, the LR tells us the relative support that a piece of evidence provides for $H_p$ or $H_d$. In this sense, the LR conveys the **probative value** of a piece of evidence. It tells us how much more likely a piece of evidence is under the prosecution's version of events when compared to the defence's version of events.

This interpretation of the LR is one of the reasons why it is advocated as a tool to quantify expert testimony. It is the role of the expert witness to present the probative value of scientific evidence within their domain of expertise to the court. The LR provides a logical means to achieve this. The fact finder can then use the probative value of evidence given by the LR to reason about the truth of $H_p$ or $H_d$. This process can clearly be seen using Bayes' theorem again, expanded on below.

Using E as a specific piece of evidence and the specific propositions $H_p$ and $H_d$, the odds form of Bayes' theorem becomes
$$\frac{\text{probability of } H_p \text{ having accounted for the evidence}}{\text{probability of } H_d \text{ having accounted for the evidence}}=\text{LR}\times\frac{\text{prior probability of } H_p}{\text{prior probability of } H_d}.$$
It can be seen that the LR updates beliefs about $H_p$ and $H_d$. Notice how beliefs about $H_p$ and $H_d$ are for the fact finder to determine, and the LR is provided by the expert witness. This is the role that the LR plays with the fact finder: the expert witness provides the LR, and in doing so provides the quantitative factor by which the fact finder should update their odds of each counsel's version of events.

## Combining evidence

LRs can also be used to consider the value of multiple pieces of evidence together. When the individual pieces of evidence are regarded as statistically independent (Chapter ...), we can to multiply their individual LRs to obtain a combined LR. If the two pieces of evidence are labelled as $E_1$ and $E_2$, then the interpretation of the LR becomes: how much more likely is it that $E_1$ **and** $E_2$ are observed if $H_p$ is true, rather than if $H_d$ is true. Combining evidence like this is the standard approach in DNA evidence evaluation. It is also becoming more popular to combine the LRs for multiple types of evidence, instead of presenting them individually. This can only be done when the propositions underlying the probability calculations are the same, and specifically are at the same proposition level. For example, there might be both glass and DNA evidence which can address an activity level proposition of the suspect breaking and entering a residential home. 

It is paramount that the assumption of statistical independence is checked when combining the LRs from multiple evidence types in this way. Unfortunately, data sources which can help scientists to determine statistical independence between evidence types is scarce in the scientific literature at this moment in time. When the statistical independence assumption does not hold true, then more complex probabilistic methods needs to be used to construct the joint LRs.

## Example: 



## Example: DNA loci



## Robustness

The LR is open to the same type of scrutiny as most other statistics. Two main reasons for this are:

1. The LR is formed using empirical observations where possible. These may be limited in their sample size and precision, they may contain bias, and they may also vary over time amongst other factors.
2. LRs formed using an expert's opinion are always subjective. Even if an opinion is widely held within a particular community of expertise, it is still subjective (though it may be less subjective than a widely disputed belief).

The degree to which an LR can withstand scrutiny due to the above reasons is termed its robustness. If an LR still seems reasonable and reliable after having assessed it from multiple perspectives (e.g. the sample size of a database which has been informed it, how appropriate that database was for the specific case circumstances, etc.) then it is robust. If an LR does not seem reasonable and reliable after this assessment process, then it is not robust. It is worth noting that an LR which is not robust might still be the best LR in the case circumstances, e.g. if there is a severe lack of data and expertise to inform the LR in the first place. 

An LR is only as robust as the probabilities from which it is formed. Any critical assessment of an LR is only a critical assessment of its underlying probabilities. It is not an assessment of the inherent properties that taking a ratio of two probabilities might give rise to. If an expert gives an LR as an order of magnitude, then the underlying order of magnitude assignments of the probabilities should be coherent with this. For example, if the LR is thought to be between 100-1000, then an order of magnitude assignment of the probability of $E$ assuming $H_d$ cannot be 0.01-0.1 as this would constrain the LR to be between 10-100.

Assessing the robustness of an LR is aided by making a distinction between types of information that the expert uses when constructing conditional probabilities. In the Primer (citation) this information is divided into two categories:

-[S]: knowledge derived from robust systematic studies, ideally published, where the relevant features have been measured and studied statistically.

-[E]: knowledge derived from personal experience, i.e. the expert's training and professional experience in the forensic specialism.

Robustness of an LR informed by knowledge from the [S] category can be assessed by focussing on the quoted studies and data therein. The study design (observational, randomised controlled trial, etc.) and its limitations might be relevant, as well as its applicability to the present case's circumstances. The robustness of studies and databases can be affected by factors such as sample size, precision of measurements, sampling bias, etc.

Robustness of an LR informed by knowledge from the [E] category can be assessed by focussing on the reliability of the expert's personal experience. This could involve the expert detailing their previous experience and its relevance. The reliability of an expert's personal experience may be informed, for example, by previous proficiency or calibration tests in which the expert has participated. The robustness of these tests may also be assessed, such as whether they were conducted blind and without knowledge that an assessment was taking place, how many times they were repeated, etc.

The [E] category is also more likely to be where expert's dispute, since it contains more subjective knowledge than [S] does. Beliefs in this category may be fringe or generally accepted amongst certain subgroups within the field of expertise. Disagreements between experts may be reasonable and can be presented to the court for examination.

The robustness of a particular LR can also be empirically assessed. This involves changing the input values of either the probabilities which determine the LR, or the values which themselves contribute to those probabilities, and inspecting how sensitive the LR is to these changes. This could also involve defining a set of reasonable values which could determine the LR, and then seeing the range of values the LR takes for this reasonable set. 

If the LR is practically unaffected by reasonable changes, or has a small range within the set of reasonable input values, then it is robust. If the LR is highly affected by minor changes, or has a large range within the set of reasonable input values, then it not so robust. 

[interactive example changing probability inputs to the LR]

## Communication

We have looked at the calculation and conceptual meaning of the LR, as well as how to assess its robustness. We now turn our attention to communicating the LR to others. Whereas the previous stages of this chapter may be conducted before evidence is presented to the court, the communication of the LR is present within the courtroom itself and it is not left to the expert witness alone. 

It cannot be stressed how important this communication stage is; even if it is agreed that the LR is the appropriate tool to convey the value of scientific evidence, its effectiveness is nothing without it being understood by those who have to use it to make decisions. This means that the LR needs to be effectively communicated **to** fact-finders and legal counsel, as well as effectively communicated **by** expert witnesses, legal counsel, and the judge if it is contained within their instructions to jurors for a particular case. It is a shared responsibility.

As shown in this chapter, LRs can be communicated using a number of different strategies. We finish the chapter with a short recap of those strategies. [Would be nice to include some of the evidence supporting each of them too.]

Suppose the following scenario:

Evidence:

- $E$: Blood-spatter pattern on the defendant's jeans. The blood has been accepted by both counsels as originating from the complainant. 

Propositions:

- $H_p$: the defendant kicked the complainant
- $H_d$: the defendant did not kick the complainant but was present during the attack. The defendant claims to have been standing some distance from the attack.

An expert witness has stated that the probability of $E$ assuming $H_p$ to be true is 0.1. The expert also stated that the probability of observing $E$ assuming $H_d$ to be true (and based on information such as where the defendant claims to have been standing during the attack) is 0.0001. This gives an LR of $\frac{0.1}{0.0001}=1000$. 

The most raw form of communicating this LR is in its numerical format. Such a statement could read like this:

> This pattern of blood-staining is 1000 times more likely to be seen if the defendant kicked the complainant, rather than if the defendant did not kick the complainant but was present during the attack and was standing in the location as described in their statement.

Converting an LR of 1000 into a verbal statement using Table \@ref(tab:verbal-scale-table) could lead to a statement such as:

> This pattern of blood-staining provides strong support for the defendant having kicked the complainant, rather than the defendant not having kicked the complainant but having been present during the attack and was standing in the location as described in their statement.

Since the conditional probabilities which determine the LR are made explicit in this example (this is not common practice), then the LR can also be communicated visually using natural frequencies in Figure \@ref(fig:freq-tree-lr-kicking):

```{r freq-tree-lr-kicking, echo=FALSE,fig.cap="The terms which contribute to the LR are shown in bold font. Since the populations we assumed are the same size, the LR is just 1000 divided by 1, or just 1000.", out.width = '80%', fig.align = 'center'}
e <- c(1, 2, 1, 3)
v <- c("10,000\nkickers", "10,000\nnon-kickers", "1000\nthis\npattern", "9000\nnot this\npattern", "1\nthis\npattern", "9999\nnot this\npattern")
freqTreeKick <- graph(edges=e, n=3, directed=FALSE)
freqTreeNonKick <- graph(edges=e, n=3, directed=FALSE)
V(freqTreeKick)$name <- v[c(1, 3, 4)]
V(freqTreeNonKick)$name <- v[c(2, 5, 6)]

colPal <- colorblind_pal()(8)
# the commented code below complicates the point
# V(freqTree)$color <- c(rep(colPal[1], 3), 
#                        colPal[4], 
#                        colPal[7],
#                        colPal[7],
#                        colPal[4])
treeCol <- c(rep(colPal[1], 3))
V(freqTreeKick)$color <- treeCol
V(freqTreeNonKick)$color <- treeCol
treeFont <- c(2, 2, 1)
V(freqTreeKick)$label.font <- treeFont
V(freqTreeNonKick)$label.font <- treeFont
par(mar = c(0, 0, 0, 0), mfrow=c(1, 2))
plot(freqTreeKick, vertex.shape="none", vertex.label=V(freqTreeKick)$name,
     vertex.label.color=V(freqTreeKick)$color, vertex.label.font=V(freqTreeKick)$label.font,
     vertex.label.cex=1.2, edge.color="grey70",  edge.width=2,
     layout=layout_as_tree(graph = freqTreeKick, root = 1),
     vertex.size=50)
# legend("bottomright", legend=c("True", "False"),
#        col=colPal[c(4,7)], bty = "n",
#        pch=16)
plot(freqTreeNonKick, vertex.shape="none", vertex.label=V(freqTreeNonKick)$name,
     vertex.label.color=V(freqTreeNonKick)$color, vertex.label.font=V(freqTreeNonKick)$label.font,
     vertex.label.cex=1.2, edge.color="grey70",  edge.width=2,
     layout=layout_as_tree(graph = freqTreeNonKick, root = 1),
     vertex.size=50)
par(mar = defMar, mfrow=c(1, 1))
```

<!-- ```{r lr-pie-kick, echo=FALSE, fig.cap="Relative size of E given H_p versus E given H_d", out.width = '80%', fig.align = 'center'} -->
<!-- df <- data.frame(prob=c("E given H_p", "E given H_d"), num=c(1000,1)) -->
<!-- bp<- ggplot(df, aes(x="", y=num, fill=prob))+ -->
<!-- geom_bar(width = 1, stat = "identity") -->
<!-- pie <- bp + coord_polar("y", start=0) + scale_fill_manual(values=c(colPal[6], colPal[7])) + theme_minimal() -->
<!-- pie -->
<!-- ``` -->

An accompanying verbal statement could be:

> Out of 10,000 kickers in an equivalent situation to the defendant in the prosecution's version of events, this blood pattern would be found on 1000 of them. Out of 10,000 non-kickers in an equivalent situation to the defendant in the defence's version of events, this blood pattern would be found on 1 of them. 

Notice how the expert did not specify a prior probability of being the kicker or not, and so we had to split the trees into two groups, one for the kickers, and one for the non-kickers.

In expert reports, the currently endorsed approach by the Forensic Science Regulator is to communicate LRs using their numerical value possibly converted into the verbal statements given in Table \@ref(tab:verbal-scale-table). The effectiveness of this method of communicating the LR (as well as others) is an active area of scientific research, and has the potential to change as we gather a better understanding of how those communications are received and used by those within the courtroom.

## More information

## Exercises